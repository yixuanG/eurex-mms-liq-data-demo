{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Process All Segments - Full Day, Max Depth\n",
    "\n",
    "This notebook orchestrates the full pipeline for all market segments:\n",
    "- Processes full trading day (not just 10-minute windows)\n",
    "- Detects and uses maximum available depth (L5, L10, L20, etc.)\n",
    "- Saves all intermediate products to Google Drive\n",
    "- Raw data stays in Colab local SSD\n",
    "\n",
    "**Prerequisites:** Run notebook `0_env_db_prep.ipynb` first to extract raw data to Colab local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Drive already mounted\n"
     ]
    }
   ],
   "source": [
    "# Check if Drive is mounted\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "drive_mount = Path('/content/drive')\n",
    "if not drive_mount.exists():\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"Google Drive mounted\")\n",
    "else:\n",
    "    print(\"Google Drive already mounted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo\n",
      "Raw data (local): /content/Sample_Eurex_20201201_10MktSegID\n",
      "Output (Drive): /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments\n"
     ]
    }
   ],
   "source": [
    "# Set paths\n",
    "REPO_DIR = \"/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo\"\n",
    "RAW_LOCAL = \"/content/Sample_Eurex_20201201_10MktSegID\"  # Colab local SSD\n",
    "OUT_DRIVE = f\"{REPO_DIR}/data_segments\"  # Output to Drive\n",
    "DATE = \"20201201\"\n",
    "\n",
    "print(f\"Repo: {REPO_DIR}\")\n",
    "print(f\"Raw data (local): {RAW_LOCAL}\")\n",
    "print(f\"Output (Drive): {OUT_DRIVE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Process specific segments\n",
    "\n",
    "Choose segments based on your interview focus:\n",
    "- **48**: Small, quick test (1.22 MB DI)\n",
    "- **821**: Medium activity (54.77 MB)\n",
    "- **589, 688, 1373**: High activity (200-400 MB)\n",
    "- **1176**: Very high activity, likely major index (9.6 GB!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Segments with Auto-Depth Detection\n",
    "\n",
    "The script automatically uses optimal depth levels for each segment from `segment_depth_summary.json`.\n",
    "\n",
    "**Options:**\n",
    "- `AUTO_DEPTH=True`: Use per-segment depth from analysis (RECOMMENDED)\n",
    "- `AUTO_DEPTH=False, MAX_LEVELS=6`: Use fixed depth for all segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ OPTIMIZED MODE - SKIP LARGE SEGMENTS\n",
      "======================================================================\n",
      "Processing segments: 688\n",
      "Skipping: 688, 1373, 1176 (too large for runtime)\n",
      "Parallelism: 2 segments at once\n",
      "Skip existing: True (safe to rerun)\n",
      "Estimated time: 1-2 hours\n",
      "Expected output: ~500 MB in Drive\n",
      "======================================================================\n",
      "\n",
      "Command:\n",
      "python \"/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/process_all_segments.py\" \\\n",
      "  --segments 688 \\\n",
      "  --src-local \"/content/Sample_Eurex_20201201_10MktSegID\" \\\n",
      "  --out-drive \"/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments\" \\\n",
      "  --date 20201201 \\\n",
      "  --auto-depth \\\n",
      "  --parallel 2 \\\n",
      "  --skip-existing\n",
      "\n",
      "======================================================================\n",
      "\n",
      "[INFO] Loading depth summary for auto-detection...\n",
      "[INFO] Loaded depth info for 10 segments\n",
      "[INFO] Checking for existing completed segments...\n",
      "[INFO] 1 segments remaining to process\n",
      "\n",
      "============================================================\n",
      "BATCH PROCESSING 1 SEGMENTS\n",
      "============================================================\n",
      "Date: 20201201\n",
      "Max levels: AUTO (per-segment from depth summary)\n",
      "  Segment   688: L3\n",
      "Parallelism: 2\n",
      "Segments: [688]\n",
      "============================================================\n",
      "\n",
      "[INFO] Using 2 parallel workers\n",
      "\n",
      "============================================================\n",
      "Starting segment 688\n",
      "============================================================\n",
      "\n",
      "\u001b[94m============================================================\u001b[0m\n",
      "\u001b[1mProcessing Segment 688 - Full Day 20201201\u001b[0m\n",
      "\u001b[94m============================================================\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94m============================================================\u001b[0m\n",
      "\u001b[1mStep 1: Slice full-day DI/DS data\u001b[0m\n",
      "\u001b[94m============================================================\u001b[0m\n",
      "\n",
      "\u001b[96mâ–¶ Slice full-day data\u001b[0m\n",
      "  Command: python /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/slice_full_day.py --seg 688 --src /content/Sample_Eurex_20201201_10MktSegID --out /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_688 --date 20201201\n",
      "[INFO] Slicing full-day data for segment 688\n",
      "  Source: /content/Sample_Eurex_20201201_10MktSegID\n",
      "  Output: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_688\n",
      "  Date: 20201201\n",
      "\n",
      "[DI] Searching...\n",
      "  Found: /content/Sample_Eurex_20201201_10MktSegID/688/DI_688_20201201.csv\n",
      "  âœ… Filtered 2911551 lines to /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_688/DI_688_20201201_fullday.csv\n",
      "\n",
      "[DS] Searching...\n",
      "  Found: /content/Sample_Eurex_20201201_10MktSegID/688/DS_688_20201201.csv\n",
      "  âœ… Filtered 1612182 lines to /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_688/DS_688_20201201_fullday.csv\n",
      "\n",
      "[IS] Searching...\n",
      "  Found: /content/Sample_Eurex_20201201_10MktSegID/688/ISC_688_20201201.csv\n",
      "  âœ… Copied 3 lines to /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_688/IS_688_20201201_fullday.csv\n",
      "\n",
      "[ISC] Searching...\n",
      "  Found: /content/Sample_Eurex_20201201_10MktSegID/688/ISC_688_20201201.csv\n",
      "  âœ… Filtered 3 lines to /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_688/ISC_688_20201201_fullday.csv\n",
      "\n",
      "[PSC] Searching...\n",
      "  Found: /content/Sample_Eurex_20201201_10MktSegID/688/PSC_688_20201201.csv\n",
      "  âœ… Filtered 9 lines to /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_688/PSC_688_20201201_fullday.csv\n",
      "\n",
      "============================================================\n",
      "SLICING SUMMARY\n",
      "============================================================\n",
      "DI  : 2,911,551 lines,   366.51 MB\n",
      "DS  : 1,612,182 lines,  2064.69 MB\n",
      "IS  :        3 lines,     0.00 MB\n",
      "ISC :        3 lines,     0.00 MB\n",
      "PSC :        9 lines,     0.00 MB\n",
      "\u001b[92mâœ… DI slice ready: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_688/DI_688_20201201_fullday.csv (366.51 MB)\u001b[0m\n",
      "\n",
      "\u001b[94m============================================================\u001b[0m\n",
      "\u001b[1mStep 2: Infer DI schema mapping\u001b[0m\n",
      "\u001b[94m============================================================\u001b[0m\n",
      "\n",
      "\u001b[96mâ–¶ Infer schema mapping\u001b[0m\n",
      "  Command: python /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/inspect_schema.py --di /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_688/DI_688_20201201_fullday.csv --out /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_688/di_mapping.json --sample-limit 500\n",
      "[OK] Wrote DI mapping JSON to: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_688/di_mapping.json\n",
      "{\n",
      "  \"md_update_action_idx\": 0,\n",
      "  \"entry_type_idx\": 2,\n",
      "  \"price_level_idx\": 1,\n",
      "  \"security_id_idx\": 7,\n",
      "  \"price_idx\": 5,\n",
      "  \"size_idx\": 6,\n",
      "  \"ts_ns_idx\": 9\n",
      "}\n",
      "\n",
      "[Preview] First 6 parsed entries:\n",
      "{'md_update_action': 0, 'entry_type': 1, 'price_level': 1, 'security_id': 64, 'price': 175.27, 'size': 621, 'ts_ns': 1606824146300664976}\n",
      "{'md_update_action': 0, 'entry_type': 1, 'price_level': 0, 'security_id': None, 'price': 177.63, 'size': 621, 'ts_ns': 1606824146300664976}\n",
      "{'md_update_action': 0, 'entry_type': 0, 'price_level': 1, 'security_id': 57, 'price': 175.26, 'size': 539, 'ts_ns': 1606824146300696239}\n",
      "{'md_update_action': 0, 'entry_type': 0, 'price_level': 1, 'security_id': 68, 'price': 175.21, 'size': 754, 'ts_ns': 1606824146300696239}\n",
      "{'md_update_action': 0, 'entry_type': 0, 'price_level': 0, 'security_id': None, 'price': 177.61, 'size': 539, 'ts_ns': 1606824146300696239}\n",
      "{'md_update_action': 0, 'entry_type': 1, 'price_level': 1, 'security_id': 9, 'price': 177.74, 'size': 102, 'ts_ns': 1606824146300810217}\n",
      "\u001b[92mâœ… Mapping saved: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_688/di_mapping.json\u001b[0m\n",
      "\n",
      "\u001b[94m============================================================\u001b[0m\n",
      "\u001b[1mStep 3: Detect maximum depth in data\u001b[0m\n",
      "\u001b[94m============================================================\u001b[0m\n",
      "\n",
      "\u001b[92mâœ… Detected max depth: L2\u001b[0m\n",
      "\n",
      "\u001b[94m============================================================\u001b[0m\n",
      "\u001b[1mStep 4: Build L2 order book snapshots\u001b[0m\n",
      "\u001b[94m============================================================\u001b[0m\n",
      "\n",
      "\u001b[96mâ–¶ Parse DI to L2 snapshots\u001b[0m\n",
      "  Command: python /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/parse_and_l5.py --seg 688 --di /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_688/DI_688_20201201_fullday.csv --mapping /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_688/di_mapping.json --out /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_688 --levels 2\n",
      "[INFO] Parsing DI file: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_688/DI_688_20201201_fullday.csv\n",
      "[INFO] Tracking top 2 levels per side\n",
      "[INFO] Memory optimization: writing snapshots in chunks of 50000\n",
      "  Processed 5000 lines, 4,666 changes...\n",
      "  Processed 10000 lines, 9,271 changes...\n",
      "  Processed 15000 lines, 13,984 changes...\n",
      "  Processed 20000 lines, 18,535 changes...\n",
      "  Processed 25000 lines, 22,943 changes...\n",
      "  Processed 30000 lines, 27,430 changes...\n",
      "  Processed 35000 lines, 31,592 changes...\n",
      "  Processed 40000 lines, 36,115 changes...\n",
      "  Processed 45000 lines, 40,634 changes...\n",
      "  Processed 50000 lines, 45,427 changes...\n",
      "  ðŸ’¾ Wrote chunk 0 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 55000 lines, 50,053 changes...\n",
      "  Processed 60000 lines, 54,697 changes...\n",
      "  Processed 65000 lines, 59,241 changes...\n",
      "  Processed 70000 lines, 63,879 changes...\n",
      "  Processed 75000 lines, 68,717 changes...\n",
      "  Processed 80000 lines, 73,287 changes...\n",
      "  Processed 85000 lines, 77,951 changes...\n",
      "  Processed 90000 lines, 82,501 changes...\n",
      "  Processed 95000 lines, 86,730 changes...\n",
      "  Processed 100000 lines, 91,004 changes...\n",
      "  Processed 105000 lines, 95,792 changes...\n",
      "  ðŸ’¾ Wrote chunk 1 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 110000 lines, 100,398 changes...\n",
      "  Processed 115000 lines, 105,079 changes...\n",
      "  Processed 120000 lines, 109,582 changes...\n",
      "  Processed 125000 lines, 113,857 changes...\n",
      "  Processed 130000 lines, 118,391 changes...\n",
      "  Processed 135000 lines, 122,933 changes...\n",
      "  Processed 140000 lines, 127,467 changes...\n",
      "  Processed 145000 lines, 131,981 changes...\n",
      "  Processed 150000 lines, 136,446 changes...\n",
      "  Processed 155000 lines, 140,859 changes...\n",
      "  Processed 160000 lines, 145,325 changes...\n",
      "  Processed 165000 lines, 149,841 changes...\n",
      "  ðŸ’¾ Wrote chunk 2 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 170000 lines, 154,481 changes...\n",
      "  Processed 175000 lines, 158,830 changes...\n",
      "  Processed 180000 lines, 163,405 changes...\n",
      "  Processed 185000 lines, 167,781 changes...\n",
      "  Processed 190000 lines, 172,323 changes...\n",
      "  Processed 195000 lines, 176,884 changes...\n",
      "  Processed 200000 lines, 181,486 changes...\n",
      "  Processed 205000 lines, 186,090 changes...\n",
      "  Processed 210000 lines, 190,482 changes...\n",
      "  Processed 215000 lines, 195,097 changes...\n",
      "  Processed 220000 lines, 199,558 changes...\n",
      "  ðŸ’¾ Wrote chunk 3 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 225000 lines, 203,932 changes...\n",
      "  Processed 230000 lines, 208,360 changes...\n",
      "  Processed 235000 lines, 213,096 changes...\n",
      "  Processed 240000 lines, 217,672 changes...\n",
      "  Processed 245000 lines, 222,072 changes...\n",
      "  Processed 250000 lines, 226,858 changes...\n",
      "  Processed 255000 lines, 231,640 changes...\n",
      "  Processed 260000 lines, 236,338 changes...\n",
      "  Processed 265000 lines, 240,895 changes...\n",
      "  Processed 270000 lines, 245,306 changes...\n",
      "  Processed 275000 lines, 249,911 changes...\n",
      "  ðŸ’¾ Wrote chunk 4 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 280000 lines, 254,501 changes...\n",
      "  Processed 285000 lines, 259,071 changes...\n",
      "  Processed 290000 lines, 263,690 changes...\n",
      "  Processed 295000 lines, 268,281 changes...\n",
      "  Processed 300000 lines, 272,904 changes...\n",
      "  Processed 305000 lines, 277,467 changes...\n",
      "  Processed 310000 lines, 282,192 changes...\n",
      "  Processed 315000 lines, 286,962 changes...\n",
      "  Processed 320000 lines, 291,851 changes...\n",
      "  Processed 325000 lines, 296,631 changes...\n",
      "  ðŸ’¾ Wrote chunk 5 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 330000 lines, 301,155 changes...\n",
      "  Processed 335000 lines, 305,893 changes...\n",
      "  Processed 340000 lines, 310,372 changes...\n",
      "  Processed 345000 lines, 314,929 changes...\n",
      "  Processed 350000 lines, 319,446 changes...\n",
      "  Processed 355000 lines, 324,141 changes...\n",
      "  Processed 360000 lines, 328,959 changes...\n",
      "  Processed 365000 lines, 333,606 changes...\n",
      "  Processed 370000 lines, 337,946 changes...\n",
      "  Processed 375000 lines, 342,423 changes...\n",
      "  Processed 380000 lines, 347,143 changes...\n",
      "  ðŸ’¾ Wrote chunk 6 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 385000 lines, 351,697 changes...\n",
      "  Processed 390000 lines, 356,422 changes...\n",
      "  Processed 395000 lines, 361,056 changes...\n",
      "  Processed 400000 lines, 365,760 changes...\n",
      "  Processed 405000 lines, 370,517 changes...\n",
      "  Processed 410000 lines, 375,107 changes...\n",
      "  Processed 415000 lines, 379,864 changes...\n",
      "  Processed 420000 lines, 384,733 changes...\n",
      "  Processed 425000 lines, 389,231 changes...\n",
      "  Processed 430000 lines, 393,645 changes...\n",
      "  Processed 435000 lines, 398,280 changes...\n",
      "  ðŸ’¾ Wrote chunk 7 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 440000 lines, 402,795 changes...\n",
      "  Processed 445000 lines, 407,534 changes...\n",
      "  Processed 450000 lines, 412,005 changes...\n",
      "  Processed 455000 lines, 416,515 changes...\n",
      "  Processed 460000 lines, 421,297 changes...\n",
      "  Processed 465000 lines, 425,681 changes...\n",
      "  Processed 470000 lines, 430,348 changes...\n",
      "  Processed 475000 lines, 435,074 changes...\n",
      "  Processed 480000 lines, 439,800 changes...\n",
      "  Processed 485000 lines, 444,100 changes...\n",
      "  Processed 490000 lines, 448,936 changes...\n",
      "  ðŸ’¾ Wrote chunk 8 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 495000 lines, 453,552 changes...\n",
      "  Processed 500000 lines, 458,269 changes...\n",
      "  Processed 505000 lines, 462,896 changes...\n",
      "  Processed 510000 lines, 467,675 changes...\n",
      "  Processed 515000 lines, 472,452 changes...\n",
      "  Processed 520000 lines, 477,186 changes...\n",
      "  Processed 525000 lines, 481,700 changes...\n",
      "  Processed 530000 lines, 486,212 changes...\n",
      "  Processed 535000 lines, 490,963 changes...\n",
      "  Processed 540000 lines, 495,640 changes...\n",
      "  ðŸ’¾ Wrote chunk 9 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 545000 lines, 500,050 changes...\n",
      "  Processed 550000 lines, 504,752 changes...\n",
      "  Processed 555000 lines, 509,438 changes...\n",
      "  Processed 560000 lines, 514,277 changes...\n",
      "  Processed 565000 lines, 518,802 changes...\n",
      "  Processed 570000 lines, 523,290 changes...\n",
      "  Processed 575000 lines, 527,975 changes...\n",
      "  Processed 580000 lines, 532,528 changes...\n",
      "  Processed 585000 lines, 537,356 changes...\n",
      "  Processed 590000 lines, 542,040 changes...\n",
      "  Processed 595000 lines, 546,687 changes...\n",
      "  ðŸ’¾ Wrote chunk 10 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 600000 lines, 551,408 changes...\n",
      "  Processed 605000 lines, 556,027 changes...\n",
      "  Processed 610000 lines, 560,466 changes...\n",
      "  Processed 615000 lines, 565,284 changes...\n",
      "  Processed 620000 lines, 570,064 changes...\n",
      "  Processed 625000 lines, 574,983 changes...\n",
      "  Processed 630000 lines, 579,590 changes...\n",
      "  Processed 635000 lines, 584,594 changes...\n",
      "  Processed 640000 lines, 589,423 changes...\n",
      "  Processed 645000 lines, 593,842 changes...\n",
      "  Processed 650000 lines, 598,172 changes...\n",
      "  ðŸ’¾ Wrote chunk 11 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 655000 lines, 602,674 changes...\n",
      "  Processed 660000 lines, 607,410 changes...\n",
      "  Processed 665000 lines, 612,057 changes...\n",
      "  Processed 670000 lines, 616,454 changes...\n",
      "  Processed 675000 lines, 621,127 changes...\n",
      "  Processed 680000 lines, 625,972 changes...\n",
      "  Processed 685000 lines, 630,641 changes...\n",
      "  Processed 690000 lines, 635,334 changes...\n",
      "  Processed 695000 lines, 640,041 changes...\n",
      "  Processed 700000 lines, 644,456 changes...\n",
      "  Processed 705000 lines, 649,173 changes...\n",
      "  ðŸ’¾ Wrote chunk 12 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 710000 lines, 653,710 changes...\n",
      "  Processed 715000 lines, 658,399 changes...\n",
      "  Processed 720000 lines, 663,003 changes...\n",
      "  Processed 725000 lines, 667,616 changes...\n",
      "  Processed 730000 lines, 672,466 changes...\n",
      "  Processed 735000 lines, 677,105 changes...\n",
      "  Processed 740000 lines, 681,743 changes...\n",
      "  Processed 745000 lines, 686,628 changes...\n",
      "  Processed 750000 lines, 691,292 changes...\n",
      "  Processed 755000 lines, 695,849 changes...\n",
      "  ðŸ’¾ Wrote chunk 13 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 760000 lines, 700,500 changes...\n",
      "  Processed 765000 lines, 705,182 changes...\n",
      "  Processed 770000 lines, 709,473 changes...\n",
      "  Processed 775000 lines, 714,045 changes...\n",
      "  Processed 780000 lines, 718,608 changes...\n",
      "  Processed 785000 lines, 723,339 changes...\n",
      "  Processed 790000 lines, 727,663 changes...\n",
      "  Processed 795000 lines, 732,330 changes...\n",
      "  Processed 800000 lines, 737,025 changes...\n",
      "  Processed 805000 lines, 741,861 changes...\n",
      "  Processed 810000 lines, 746,562 changes...\n",
      "  ðŸ’¾ Wrote chunk 14 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 815000 lines, 750,996 changes...\n",
      "  Processed 820000 lines, 755,616 changes...\n",
      "  Processed 825000 lines, 760,113 changes...\n",
      "  Processed 830000 lines, 764,504 changes...\n",
      "  Processed 835000 lines, 768,911 changes...\n",
      "  Processed 840000 lines, 773,382 changes...\n",
      "  Processed 845000 lines, 777,992 changes...\n",
      "  Processed 850000 lines, 782,398 changes...\n",
      "  Processed 855000 lines, 786,896 changes...\n",
      "  Processed 860000 lines, 791,363 changes...\n",
      "  Processed 865000 lines, 795,665 changes...\n",
      "  ðŸ’¾ Wrote chunk 15 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 870000 lines, 800,104 changes...\n",
      "  Processed 875000 lines, 804,446 changes...\n",
      "  Processed 880000 lines, 808,807 changes...\n",
      "  Processed 885000 lines, 813,032 changes...\n",
      "  Processed 890000 lines, 817,313 changes...\n",
      "  Processed 895000 lines, 821,782 changes...\n",
      "  Processed 900000 lines, 826,240 changes...\n",
      "  Processed 905000 lines, 830,951 changes...\n",
      "  Processed 910000 lines, 835,675 changes...\n",
      "  Processed 915000 lines, 840,400 changes...\n",
      "  Processed 920000 lines, 845,154 changes...\n",
      "  ðŸ’¾ Wrote chunk 16 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 925000 lines, 850,179 changes...\n",
      "  Processed 930000 lines, 854,622 changes...\n",
      "  Processed 935000 lines, 859,093 changes...\n",
      "  Processed 940000 lines, 864,004 changes...\n",
      "  Processed 945000 lines, 868,579 changes...\n",
      "  Processed 950000 lines, 872,957 changes...\n",
      "  Processed 955000 lines, 877,505 changes...\n",
      "  Processed 960000 lines, 882,359 changes...\n",
      "  Processed 965000 lines, 887,168 changes...\n",
      "  Processed 970000 lines, 891,585 changes...\n",
      "  Processed 975000 lines, 896,420 changes...\n",
      "  ðŸ’¾ Wrote chunk 17 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 980000 lines, 901,015 changes...\n",
      "  Processed 985000 lines, 905,681 changes...\n",
      "  Processed 990000 lines, 910,399 changes...\n",
      "  Processed 995000 lines, 914,984 changes...\n",
      "  Processed 1000000 lines, 919,572 changes...\n",
      "  Processed 1005000 lines, 924,101 changes...\n",
      "  Processed 1010000 lines, 928,755 changes...\n",
      "  Processed 1015000 lines, 933,364 changes...\n",
      "  Processed 1020000 lines, 937,893 changes...\n",
      "  Processed 1025000 lines, 942,579 changes...\n",
      "  Processed 1030000 lines, 947,250 changes...\n",
      "  ðŸ’¾ Wrote chunk 18 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 1035000 lines, 951,400 changes...\n",
      "  Processed 1040000 lines, 955,920 changes...\n",
      "  Processed 1045000 lines, 960,629 changes...\n",
      "  Processed 1050000 lines, 965,278 changes...\n",
      "  Processed 1055000 lines, 969,896 changes...\n",
      "  Processed 1060000 lines, 974,500 changes...\n",
      "  Processed 1065000 lines, 979,048 changes...\n",
      "  Processed 1070000 lines, 983,453 changes...\n",
      "  Processed 1075000 lines, 987,843 changes...\n",
      "  Processed 1080000 lines, 992,466 changes...\n",
      "  Processed 1085000 lines, 997,139 changes...\n",
      "  ðŸ’¾ Wrote chunk 19 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 1090000 lines, 1,001,732 changes...\n",
      "  Processed 1095000 lines, 1,006,264 changes...\n",
      "  Processed 1100000 lines, 1,010,910 changes...\n",
      "  Processed 1105000 lines, 1,015,613 changes...\n",
      "  Processed 1110000 lines, 1,020,270 changes...\n",
      "  Processed 1115000 lines, 1,024,949 changes...\n",
      "  Processed 1120000 lines, 1,029,473 changes...\n",
      "  Processed 1125000 lines, 1,033,950 changes...\n",
      "  Processed 1130000 lines, 1,038,604 changes...\n",
      "  Processed 1135000 lines, 1,043,220 changes...\n",
      "  Processed 1140000 lines, 1,047,708 changes...\n",
      "  ðŸ’¾ Wrote chunk 20 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 1145000 lines, 1,052,390 changes...\n",
      "  Processed 1150000 lines, 1,056,965 changes...\n",
      "  Processed 1155000 lines, 1,061,405 changes...\n",
      "  Processed 1160000 lines, 1,066,041 changes...\n",
      "  Processed 1165000 lines, 1,070,777 changes...\n",
      "  Processed 1170000 lines, 1,075,553 changes...\n",
      "  Processed 1175000 lines, 1,079,904 changes...\n",
      "  Processed 1180000 lines, 1,084,279 changes...\n",
      "  Processed 1185000 lines, 1,088,953 changes...\n",
      "  Processed 1190000 lines, 1,093,616 changes...\n",
      "  Processed 1195000 lines, 1,098,197 changes...\n",
      "  ðŸ’¾ Wrote chunk 21 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 1200000 lines, 1,102,380 changes...\n",
      "  Processed 1205000 lines, 1,106,933 changes...\n",
      "  Processed 1210000 lines, 1,111,500 changes...\n",
      "  Processed 1215000 lines, 1,116,207 changes...\n",
      "  Processed 1220000 lines, 1,120,804 changes...\n",
      "  Processed 1225000 lines, 1,125,006 changes...\n",
      "  Processed 1230000 lines, 1,129,208 changes...\n",
      "  Processed 1235000 lines, 1,133,261 changes...\n",
      "  Processed 1240000 lines, 1,137,766 changes...\n",
      "  Processed 1245000 lines, 1,142,425 changes...\n",
      "  Processed 1250000 lines, 1,146,918 changes...\n",
      "  ðŸ’¾ Wrote chunk 22 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 1255000 lines, 1,151,558 changes...\n",
      "  Processed 1260000 lines, 1,156,013 changes...\n",
      "  Processed 1265000 lines, 1,160,798 changes...\n",
      "  Processed 1270000 lines, 1,165,415 changes...\n",
      "  Processed 1275000 lines, 1,170,012 changes...\n",
      "  Processed 1280000 lines, 1,174,374 changes...\n",
      "  Processed 1285000 lines, 1,178,937 changes...\n",
      "  Processed 1290000 lines, 1,183,433 changes...\n",
      "  Processed 1295000 lines, 1,187,926 changes...\n",
      "  Processed 1300000 lines, 1,192,473 changes...\n",
      "  Processed 1305000 lines, 1,197,101 changes...\n",
      "  ðŸ’¾ Wrote chunk 23 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 1310000 lines, 1,201,523 changes...\n",
      "  Processed 1315000 lines, 1,206,137 changes...\n",
      "  Processed 1320000 lines, 1,210,392 changes...\n",
      "  Processed 1325000 lines, 1,215,013 changes...\n",
      "  Processed 1330000 lines, 1,219,484 changes...\n",
      "  Processed 1335000 lines, 1,223,868 changes...\n",
      "  Processed 1340000 lines, 1,228,378 changes...\n",
      "  Processed 1345000 lines, 1,232,829 changes...\n",
      "  Processed 1350000 lines, 1,237,223 changes...\n",
      "  Processed 1355000 lines, 1,241,756 changes...\n",
      "  Processed 1360000 lines, 1,246,307 changes...\n",
      "  ðŸ’¾ Wrote chunk 24 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 1365000 lines, 1,250,754 changes...\n",
      "  Processed 1370000 lines, 1,255,335 changes...\n",
      "  Processed 1375000 lines, 1,259,546 changes...\n",
      "  Processed 1380000 lines, 1,263,976 changes...\n",
      "  Processed 1385000 lines, 1,268,584 changes...\n",
      "  Processed 1390000 lines, 1,273,157 changes...\n",
      "  Processed 1395000 lines, 1,277,703 changes...\n",
      "  Processed 1400000 lines, 1,282,278 changes...\n",
      "  Processed 1405000 lines, 1,286,773 changes...\n",
      "  Processed 1410000 lines, 1,291,431 changes...\n",
      "  Processed 1415000 lines, 1,296,004 changes...\n",
      "  ðŸ’¾ Wrote chunk 25 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 1420000 lines, 1,300,545 changes...\n",
      "  Processed 1425000 lines, 1,305,181 changes...\n",
      "  Processed 1430000 lines, 1,309,777 changes...\n",
      "  Processed 1435000 lines, 1,314,261 changes...\n",
      "  Processed 1440000 lines, 1,318,891 changes...\n",
      "  Processed 1445000 lines, 1,323,534 changes...\n",
      "  Processed 1450000 lines, 1,328,003 changes...\n",
      "  Processed 1455000 lines, 1,332,629 changes...\n",
      "  Processed 1460000 lines, 1,337,190 changes...\n",
      "  Processed 1465000 lines, 1,341,710 changes...\n",
      "  Processed 1470000 lines, 1,346,199 changes...\n",
      "  ðŸ’¾ Wrote chunk 26 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 1475000 lines, 1,350,744 changes...\n",
      "  Processed 1480000 lines, 1,355,249 changes...\n",
      "  Processed 1485000 lines, 1,359,851 changes...\n",
      "  Processed 1490000 lines, 1,364,391 changes...\n",
      "  Processed 1495000 lines, 1,368,956 changes...\n",
      "  Processed 1500000 lines, 1,373,565 changes...\n",
      "  Processed 1505000 lines, 1,378,107 changes...\n",
      "  Processed 1510000 lines, 1,382,645 changes...\n",
      "  Processed 1515000 lines, 1,387,315 changes...\n",
      "  Processed 1520000 lines, 1,391,919 changes...\n",
      "  Processed 1525000 lines, 1,396,661 changes...\n",
      "  ðŸ’¾ Wrote chunk 27 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 1530000 lines, 1,401,189 changes...\n",
      "  Processed 1535000 lines, 1,405,690 changes...\n",
      "  Processed 1540000 lines, 1,410,468 changes...\n",
      "  Processed 1545000 lines, 1,415,244 changes...\n",
      "  Processed 1550000 lines, 1,419,970 changes...\n",
      "  Processed 1555000 lines, 1,424,707 changes...\n",
      "  Processed 1560000 lines, 1,429,701 changes...\n",
      "  Processed 1565000 lines, 1,433,975 changes...\n",
      "  Processed 1570000 lines, 1,438,654 changes...\n",
      "  Processed 1575000 lines, 1,443,382 changes...\n",
      "  Processed 1580000 lines, 1,448,032 changes...\n",
      "  ðŸ’¾ Wrote chunk 28 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 1585000 lines, 1,452,552 changes...\n",
      "  Processed 1590000 lines, 1,457,162 changes...\n",
      "  Processed 1595000 lines, 1,461,875 changes...\n",
      "  Processed 1600000 lines, 1,466,533 changes...\n",
      "  Processed 1605000 lines, 1,471,054 changes...\n",
      "  Processed 1610000 lines, 1,475,588 changes...\n",
      "  Processed 1615000 lines, 1,480,073 changes...\n",
      "  Processed 1620000 lines, 1,484,431 changes...\n",
      "  Processed 1625000 lines, 1,488,312 changes...\n",
      "  Processed 1630000 lines, 1,492,291 changes...\n",
      "  Processed 1635000 lines, 1,497,071 changes...\n",
      "  ðŸ’¾ Wrote chunk 29 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 1640000 lines, 1,501,077 changes...\n",
      "  Processed 1645000 lines, 1,505,853 changes...\n",
      "  Processed 1650000 lines, 1,510,660 changes...\n",
      "  Processed 1655000 lines, 1,515,327 changes...\n",
      "  Processed 1660000 lines, 1,519,832 changes...\n",
      "  Processed 1665000 lines, 1,524,277 changes...\n",
      "  Processed 1670000 lines, 1,528,670 changes...\n",
      "  Processed 1675000 lines, 1,533,186 changes...\n",
      "  Processed 1680000 lines, 1,537,653 changes...\n",
      "  Processed 1685000 lines, 1,542,053 changes...\n",
      "  Processed 1690000 lines, 1,546,749 changes...\n",
      "  ðŸ’¾ Wrote chunk 30 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 1695000 lines, 1,551,353 changes...\n",
      "  Processed 1700000 lines, 1,555,693 changes...\n",
      "  Processed 1705000 lines, 1,560,173 changes...\n",
      "  Processed 1710000 lines, 1,564,743 changes...\n",
      "  Processed 1715000 lines, 1,569,421 changes...\n",
      "  Processed 1720000 lines, 1,573,845 changes...\n",
      "  Processed 1725000 lines, 1,578,442 changes...\n",
      "  Processed 1730000 lines, 1,583,125 changes...\n",
      "  Processed 1735000 lines, 1,587,862 changes...\n",
      "  Processed 1740000 lines, 1,592,571 changes...\n",
      "  Processed 1745000 lines, 1,597,416 changes...\n",
      "  ðŸ’¾ Wrote chunk 31 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 1750000 lines, 1,602,180 changes...\n",
      "  Processed 1755000 lines, 1,606,371 changes...\n",
      "  Processed 1760000 lines, 1,611,069 changes...\n",
      "  Processed 1765000 lines, 1,615,720 changes...\n",
      "  Processed 1770000 lines, 1,620,043 changes...\n",
      "  Processed 1775000 lines, 1,624,750 changes...\n",
      "  Processed 1780000 lines, 1,629,485 changes...\n",
      "  Processed 1785000 lines, 1,634,241 changes...\n",
      "  Processed 1790000 lines, 1,638,920 changes...\n",
      "  Processed 1795000 lines, 1,643,730 changes...\n",
      "  Processed 1800000 lines, 1,648,295 changes...\n",
      "  ðŸ’¾ Wrote chunk 32 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 1805000 lines, 1,652,601 changes...\n",
      "  Processed 1810000 lines, 1,656,889 changes...\n",
      "  Processed 1815000 lines, 1,661,287 changes...\n",
      "  Processed 1820000 lines, 1,665,737 changes...\n",
      "  Processed 1825000 lines, 1,670,421 changes...\n",
      "  Processed 1830000 lines, 1,675,179 changes...\n",
      "  Processed 1835000 lines, 1,679,825 changes...\n",
      "  Processed 1840000 lines, 1,684,405 changes...\n",
      "  Processed 1845000 lines, 1,689,009 changes...\n",
      "  Processed 1850000 lines, 1,693,516 changes...\n",
      "  Processed 1855000 lines, 1,697,880 changes...\n",
      "  ðŸ’¾ Wrote chunk 33 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 1860000 lines, 1,702,068 changes...\n",
      "  Processed 1865000 lines, 1,706,768 changes...\n",
      "  Processed 1870000 lines, 1,711,347 changes...\n",
      "  Processed 1875000 lines, 1,716,287 changes...\n",
      "  Processed 1880000 lines, 1,720,800 changes...\n",
      "  Processed 1885000 lines, 1,725,480 changes...\n",
      "  Processed 1890000 lines, 1,730,459 changes...\n",
      "  Processed 1895000 lines, 1,735,231 changes...\n",
      "  Processed 1900000 lines, 1,740,071 changes...\n",
      "  Processed 1905000 lines, 1,745,030 changes...\n",
      "  Processed 1910000 lines, 1,749,982 changes...\n",
      "  ðŸ’¾ Wrote chunk 34 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 1915000 lines, 1,754,461 changes...\n",
      "  Processed 1920000 lines, 1,759,368 changes...\n",
      "  Processed 1925000 lines, 1,764,187 changes...\n",
      "  Processed 1930000 lines, 1,768,952 changes...\n",
      "  Processed 1935000 lines, 1,773,732 changes...\n",
      "  Processed 1940000 lines, 1,778,319 changes...\n",
      "  Processed 1945000 lines, 1,783,110 changes...\n",
      "  Processed 1950000 lines, 1,787,944 changes...\n",
      "  Processed 1955000 lines, 1,792,733 changes...\n",
      "  Processed 1960000 lines, 1,797,335 changes...\n",
      "  ðŸ’¾ Wrote chunk 35 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 1965000 lines, 1,801,893 changes...\n",
      "  Processed 1970000 lines, 1,806,567 changes...\n",
      "  Processed 1975000 lines, 1,811,193 changes...\n",
      "  Processed 1980000 lines, 1,816,043 changes...\n",
      "  Processed 1985000 lines, 1,820,902 changes...\n",
      "  Processed 1990000 lines, 1,825,406 changes...\n",
      "  Processed 1995000 lines, 1,829,887 changes...\n",
      "  Processed 2000000 lines, 1,834,620 changes...\n",
      "  Processed 2005000 lines, 1,839,324 changes...\n",
      "  Processed 2010000 lines, 1,844,120 changes...\n",
      "  Processed 2015000 lines, 1,848,345 changes...\n",
      "  ðŸ’¾ Wrote chunk 36 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 2020000 lines, 1,852,897 changes...\n",
      "  Processed 2025000 lines, 1,857,493 changes...\n",
      "  Processed 2030000 lines, 1,862,317 changes...\n",
      "  Processed 2035000 lines, 1,866,762 changes...\n",
      "  Processed 2040000 lines, 1,871,461 changes...\n",
      "  Processed 2045000 lines, 1,876,133 changes...\n",
      "  Processed 2050000 lines, 1,880,669 changes...\n",
      "  Processed 2055000 lines, 1,885,209 changes...\n",
      "  Processed 2060000 lines, 1,889,969 changes...\n",
      "  Processed 2065000 lines, 1,894,626 changes...\n",
      "  Processed 2070000 lines, 1,899,231 changes...\n",
      "  ðŸ’¾ Wrote chunk 37 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 2075000 lines, 1,903,579 changes...\n",
      "  Processed 2080000 lines, 1,907,946 changes...\n",
      "  Processed 2085000 lines, 1,912,174 changes...\n",
      "  Processed 2090000 lines, 1,916,692 changes...\n",
      "  Processed 2095000 lines, 1,921,103 changes...\n",
      "  Processed 2100000 lines, 1,925,681 changes...\n",
      "  Processed 2105000 lines, 1,930,190 changes...\n",
      "  Processed 2110000 lines, 1,934,699 changes...\n",
      "  Processed 2115000 lines, 1,939,538 changes...\n",
      "  Processed 2120000 lines, 1,944,385 changes...\n",
      "  Processed 2125000 lines, 1,949,407 changes...\n",
      "  ðŸ’¾ Wrote chunk 38 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 2130000 lines, 1,954,006 changes...\n",
      "  Processed 2135000 lines, 1,958,448 changes...\n",
      "  Processed 2140000 lines, 1,962,972 changes...\n",
      "  Processed 2145000 lines, 1,967,151 changes...\n",
      "  Processed 2150000 lines, 1,971,648 changes...\n",
      "  Processed 2155000 lines, 1,976,308 changes...\n",
      "  Processed 2160000 lines, 1,980,996 changes...\n",
      "  Processed 2165000 lines, 1,985,851 changes...\n",
      "  Processed 2170000 lines, 1,990,262 changes...\n",
      "  Processed 2175000 lines, 1,994,930 changes...\n",
      "  Processed 2180000 lines, 1,999,670 changes...\n",
      "  ðŸ’¾ Wrote chunk 39 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 2185000 lines, 2,004,460 changes...\n",
      "  Processed 2190000 lines, 2,008,877 changes...\n",
      "  Processed 2195000 lines, 2,013,153 changes...\n",
      "  Processed 2200000 lines, 2,017,458 changes...\n",
      "  Processed 2205000 lines, 2,021,721 changes...\n",
      "  Processed 2210000 lines, 2,026,277 changes...\n",
      "  Processed 2215000 lines, 2,030,855 changes...\n",
      "  Processed 2220000 lines, 2,035,391 changes...\n",
      "  Processed 2225000 lines, 2,039,855 changes...\n",
      "  Processed 2230000 lines, 2,044,395 changes...\n",
      "  Processed 2235000 lines, 2,048,978 changes...\n",
      "  ðŸ’¾ Wrote chunk 40 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 2240000 lines, 2,053,489 changes...\n",
      "  Processed 2245000 lines, 2,057,949 changes...\n",
      "  Processed 2250000 lines, 2,062,332 changes...\n",
      "  Processed 2255000 lines, 2,066,842 changes...\n",
      "  Processed 2260000 lines, 2,071,363 changes...\n",
      "  Processed 2265000 lines, 2,075,831 changes...\n",
      "  Processed 2270000 lines, 2,080,536 changes...\n",
      "  Processed 2275000 lines, 2,085,171 changes...\n",
      "  Processed 2280000 lines, 2,089,973 changes...\n",
      "  Processed 2285000 lines, 2,094,692 changes...\n",
      "  Processed 2290000 lines, 2,099,163 changes...\n",
      "  ðŸ’¾ Wrote chunk 41 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 2295000 lines, 2,103,554 changes...\n",
      "  Processed 2300000 lines, 2,108,217 changes...\n",
      "  Processed 2305000 lines, 2,112,851 changes...\n",
      "  Processed 2310000 lines, 2,117,322 changes...\n",
      "  Processed 2315000 lines, 2,121,856 changes...\n",
      "  Processed 2320000 lines, 2,126,427 changes...\n",
      "  Processed 2325000 lines, 2,131,059 changes...\n",
      "  Processed 2330000 lines, 2,135,523 changes...\n",
      "  Processed 2335000 lines, 2,140,038 changes...\n",
      "  Processed 2340000 lines, 2,144,560 changes...\n",
      "  Processed 2345000 lines, 2,149,189 changes...\n",
      "  ðŸ’¾ Wrote chunk 42 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 2350000 lines, 2,153,601 changes...\n",
      "  Processed 2355000 lines, 2,158,075 changes...\n",
      "  Processed 2360000 lines, 2,162,918 changes...\n",
      "  Processed 2365000 lines, 2,167,421 changes...\n",
      "  Processed 2370000 lines, 2,171,793 changes...\n",
      "  Processed 2375000 lines, 2,176,271 changes...\n",
      "  Processed 2380000 lines, 2,180,825 changes...\n",
      "  Processed 2385000 lines, 2,185,234 changes...\n",
      "  Processed 2390000 lines, 2,189,309 changes...\n",
      "  Processed 2395000 lines, 2,193,841 changes...\n",
      "  Processed 2400000 lines, 2,198,250 changes...\n",
      "  ðŸ’¾ Wrote chunk 43 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 2405000 lines, 2,202,474 changes...\n",
      "  Processed 2410000 lines, 2,206,871 changes...\n",
      "  Processed 2415000 lines, 2,211,295 changes...\n",
      "  Processed 2420000 lines, 2,215,828 changes...\n",
      "  Processed 2425000 lines, 2,219,993 changes...\n",
      "  Processed 2430000 lines, 2,224,230 changes...\n",
      "  Processed 2435000 lines, 2,228,699 changes...\n",
      "  Processed 2440000 lines, 2,233,226 changes...\n",
      "  Processed 2445000 lines, 2,237,749 changes...\n",
      "  Processed 2450000 lines, 2,242,214 changes...\n",
      "  Processed 2455000 lines, 2,246,623 changes...\n",
      "  ðŸ’¾ Wrote chunk 44 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 2460000 lines, 2,251,186 changes...\n",
      "  Processed 2465000 lines, 2,255,779 changes...\n",
      "  Processed 2470000 lines, 2,260,114 changes...\n",
      "  Processed 2475000 lines, 2,264,703 changes...\n",
      "  Processed 2480000 lines, 2,269,076 changes...\n",
      "  Processed 2485000 lines, 2,273,687 changes...\n",
      "  Processed 2490000 lines, 2,278,039 changes...\n",
      "  Processed 2495000 lines, 2,282,289 changes...\n",
      "  Processed 2500000 lines, 2,287,082 changes...\n",
      "  Processed 2505000 lines, 2,291,954 changes...\n",
      "  Processed 2510000 lines, 2,296,523 changes...\n",
      "  ðŸ’¾ Wrote chunk 45 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 2515000 lines, 2,300,799 changes...\n",
      "  Processed 2520000 lines, 2,305,330 changes...\n",
      "  Processed 2525000 lines, 2,309,818 changes...\n",
      "  Processed 2530000 lines, 2,314,290 changes...\n",
      "  Processed 2535000 lines, 2,318,901 changes...\n",
      "  Processed 2540000 lines, 2,323,485 changes...\n",
      "  Processed 2545000 lines, 2,327,989 changes...\n",
      "  Processed 2550000 lines, 2,332,728 changes...\n",
      "  Processed 2555000 lines, 2,337,172 changes...\n",
      "  Processed 2560000 lines, 2,341,691 changes...\n",
      "  Processed 2565000 lines, 2,346,434 changes...\n",
      "  ðŸ’¾ Wrote chunk 46 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 2570000 lines, 2,350,928 changes...\n",
      "  Processed 2575000 lines, 2,355,632 changes...\n",
      "  Processed 2580000 lines, 2,360,120 changes...\n",
      "  Processed 2585000 lines, 2,364,694 changes...\n",
      "  Processed 2590000 lines, 2,368,831 changes...\n",
      "  Processed 2595000 lines, 2,373,415 changes...\n",
      "  Processed 2600000 lines, 2,378,073 changes...\n",
      "  Processed 2605000 lines, 2,382,639 changes...\n",
      "  Processed 2610000 lines, 2,387,159 changes...\n",
      "  Processed 2615000 lines, 2,391,569 changes...\n",
      "  Processed 2620000 lines, 2,395,864 changes...\n",
      "  ðŸ’¾ Wrote chunk 47 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 2625000 lines, 2,400,372 changes...\n",
      "  Processed 2630000 lines, 2,404,929 changes...\n",
      "  Processed 2635000 lines, 2,409,763 changes...\n",
      "  Processed 2640000 lines, 2,414,431 changes...\n",
      "  Processed 2645000 lines, 2,418,896 changes...\n",
      "  Processed 2650000 lines, 2,423,395 changes...\n",
      "  Processed 2655000 lines, 2,427,762 changes...\n",
      "  Processed 2660000 lines, 2,432,268 changes...\n",
      "  Processed 2665000 lines, 2,436,741 changes...\n",
      "  Processed 2670000 lines, 2,441,224 changes...\n",
      "  Processed 2675000 lines, 2,445,803 changes...\n",
      "  ðŸ’¾ Wrote chunk 48 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 2680000 lines, 2,450,260 changes...\n",
      "  Processed 2685000 lines, 2,454,808 changes...\n",
      "  Processed 2690000 lines, 2,459,302 changes...\n",
      "  Processed 2695000 lines, 2,463,815 changes...\n",
      "  Processed 2700000 lines, 2,468,272 changes...\n",
      "  Processed 2705000 lines, 2,472,806 changes...\n",
      "  Processed 2710000 lines, 2,477,267 changes...\n",
      "  Processed 2715000 lines, 2,481,538 changes...\n",
      "  Processed 2720000 lines, 2,485,497 changes...\n",
      "  Processed 2725000 lines, 2,489,953 changes...\n",
      "  Processed 2730000 lines, 2,494,146 changes...\n",
      "  Processed 2735000 lines, 2,498,516 changes...\n",
      "  ðŸ’¾ Wrote chunk 49 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 2740000 lines, 2,502,962 changes...\n",
      "  Processed 2745000 lines, 2,507,084 changes...\n",
      "  Processed 2750000 lines, 2,511,078 changes...\n",
      "  Processed 2755000 lines, 2,515,332 changes...\n",
      "  Processed 2760000 lines, 2,519,825 changes...\n",
      "  Processed 2765000 lines, 2,524,423 changes...\n",
      "  Processed 2770000 lines, 2,529,209 changes...\n",
      "  Processed 2775000 lines, 2,533,687 changes...\n",
      "  Processed 2780000 lines, 2,538,232 changes...\n",
      "  Processed 2785000 lines, 2,542,846 changes...\n",
      "  Processed 2790000 lines, 2,547,433 changes...\n",
      "  ðŸ’¾ Wrote chunk 50 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 2795000 lines, 2,551,988 changes...\n",
      "  Processed 2800000 lines, 2,556,435 changes...\n",
      "  Processed 2805000 lines, 2,560,544 changes...\n",
      "  Processed 2810000 lines, 2,564,888 changes...\n",
      "  Processed 2815000 lines, 2,569,166 changes...\n",
      "  Processed 2820000 lines, 2,573,304 changes...\n",
      "  Processed 2825000 lines, 2,577,690 changes...\n",
      "  Processed 2830000 lines, 2,582,004 changes...\n",
      "  Processed 2835000 lines, 2,586,207 changes...\n",
      "  Processed 2840000 lines, 2,590,776 changes...\n",
      "  Processed 2845000 lines, 2,595,155 changes...\n",
      "  Processed 2850000 lines, 2,599,581 changes...\n",
      "  ðŸ’¾ Wrote chunk 51 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 2855000 lines, 2,603,982 changes...\n",
      "  Processed 2860000 lines, 2,608,132 changes...\n",
      "  Processed 2865000 lines, 2,612,813 changes...\n",
      "  Processed 2870000 lines, 2,617,173 changes...\n",
      "  Processed 2875000 lines, 2,621,610 changes...\n",
      "  Processed 2880000 lines, 2,625,959 changes...\n",
      "  Processed 2885000 lines, 2,630,605 changes...\n",
      "  Processed 2890000 lines, 2,635,196 changes...\n",
      "  Processed 2895000 lines, 2,639,678 changes...\n",
      "  Processed 2900000 lines, 2,644,171 changes...\n",
      "  Processed 2905000 lines, 2,648,606 changes...\n",
      "  ðŸ’¾ Wrote chunk 52 (50,000 snapshots) to disk, freed memory\n",
      "  Processed 2910000 lines, 2,652,711 changes...\n",
      "  ðŸ’¾ Wrote chunk 53 (4,131 snapshots) to disk, freed memory\n",
      "[INFO] Processing complete:\n",
      "  Lines: 2911551\n",
      "  Events: 5372852\n",
      "  Changes: 2654131\n",
      "  Chunks written: 54\n",
      "[INFO] Merging 54 pre-sorted chunks...\n",
      "[INFO] Using batched merge (batches of 20 chunks)\n",
      "  Merging batch 1 (chunks 1-20)...\n",
      "  Merging batch 2 (chunks 21-40)...\n",
      "  Merging batch 3 (chunks 41-54)...\n",
      "[INFO] Created 3 merged batches, final merge...\n",
      "[INFO] Final dataset: 2,654,131 snapshots\n",
      "[INFO] Cleaning up temporary chunks...\n",
      "[OK] Wrote: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_688/l2/l2_snapshots_seg688.parquet rows= 2654131\n",
      "[OK] Wrote: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_688/l2/l2_snapshots_seg688.csv rows= 2654131\n",
      "\n",
      "[Preview] First 3 rows:\n",
      "                 ts_ns  bid_price_1  bid_size_1  ...  ask_size_5  security_id  action\n",
      "0  1606781709480499641       175.30         1.0  ...        None            1       0\n",
      "1  1606781709480499641       175.29        10.0  ...        None            1       0\n",
      "2  1606781709480499641       175.29        10.0  ...        None            1       0\n",
      "\n",
      "[3 rows x 23 columns]\n",
      "\u001b[92mâœ… Snapshots ready: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_688/l2/l2_snapshots_seg688.parquet (39.73 MB)\u001b[0m\n",
      "\n",
      "\u001b[94m============================================================\u001b[0m\n",
      "\u001b[1mStep 5: Aggregate to 1-second metrics\u001b[0m\n",
      "\u001b[94m============================================================\u001b[0m\n",
      "\n",
      "\u001b[96mâ–¶ Aggregate to 1s metrics\u001b[0m\n",
      "  Command: python /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py --seg 688 --l5 /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_688/l2/l2_snapshots_seg688.parquet --di /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_688/DI_688_20201201_fullday.csv --mapping /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_688/di_mapping.json --out /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_688\n",
      "[INFO] Loading L5 snapshots from /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_688/l2/l2_snapshots_seg688.parquet...\n",
      "[INFO] Loaded 2,654,131 L5 snapshots\n",
      "[INFO] Pre-computing update/cancel counts from DI file (366.5 MB)...\n",
      "  Processed 100,000 DI lines, 114,777 events...\n",
      "  Processed 200,000 DI lines, 227,380 events...\n",
      "  Processed 300,000 DI lines, 340,329 events...\n",
      "  Processed 400,000 DI lines, 453,851 events...\n",
      "  Processed 500,000 DI lines, 567,832 events...\n",
      "  Processed 600,000 DI lines, 682,415 events...\n",
      "  Processed 700,000 DI lines, 797,197 events...\n",
      "  Processed 800,000 DI lines, 912,049 events...\n",
      "  Processed 900,000 DI lines, 1,024,721 events...\n",
      "  Processed 1,000,000 DI lines, 1,140,405 events...\n",
      "  Processed 1,100,000 DI lines, 1,252,420 events...\n",
      "  Processed 1,200,000 DI lines, 1,365,912 events...\n",
      "  Processed 1,300,000 DI lines, 1,478,163 events...\n",
      "  Processed 1,400,000 DI lines, 1,590,245 events...\n",
      "  Processed 1,500,000 DI lines, 1,704,735 events...\n",
      "  Processed 1,600,000 DI lines, 1,821,201 events...\n",
      "  Processed 1,700,000 DI lines, 1,934,632 events...\n",
      "  Processed 1,800,000 DI lines, 2,049,948 events...\n",
      "  Processed 1,900,000 DI lines, 2,165,688 events...\n",
      "  Processed 2,000,000 DI lines, 2,284,947 events...\n",
      "  Processed 2,100,000 DI lines, 2,405,443 events...\n",
      "  Processed 2,200,000 DI lines, 2,519,462 events...\n",
      "  Processed 2,300,000 DI lines, 2,631,427 events...\n",
      "  Processed 2,400,000 DI lines, 2,742,906 events...\n",
      "  Processed 2,500,000 DI lines, 2,853,842 events...\n",
      "  Processed 2,600,000 DI lines, 2,966,133 events...\n",
      "  Processed 2,700,000 DI lines, 3,078,584 events...\n",
      "  Processed 2,800,000 DI lines, 3,190,255 events...\n",
      "  Processed 2,900,000 DI lines, 3,303,715 events...\n",
      "[INFO] Parsed 2,911,551 DI lines, extracted 3,317,280 events\n",
      "[INFO] Aggregating event counts by second...\n",
      "[INFO] Computed counts for 1,108,000 unique (security, second) pairs\n",
      "[INFO] Aggregating snapshots by second...\n",
      "[INFO] Processing 974,894 unique (security, second) groups...\n",
      "[INFO] Large dataset detected - using chunked aggregation\n",
      "[INFO] Processing 246 securities...\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "  Progress: 10/246 securities\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "  Progress: 20/246 securities\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "  Progress: 30/246 securities\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "  Progress: 40/246 securities\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "  Progress: 50/246 securities\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "  Progress: 60/246 securities\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "  Progress: 70/246 securities\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "  Progress: 80/246 securities\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "  Progress: 90/246 securities\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "  Progress: 100/246 securities\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "  Progress: 110/246 securities\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "  Progress: 120/246 securities\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "  Progress: 130/246 securities\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "  Progress: 140/246 securities\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "  Progress: 150/246 securities\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "  Progress: 160/246 securities\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "  Progress: 170/246 securities\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "  Progress: 180/246 securities\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "  Progress: 190/246 securities\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "  Progress: 200/246 securities\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "  Progress: 210/246 securities\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "  Progress: 220/246 securities\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "  Progress: 230/246 securities\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "  Progress: 240/246 securities\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "  Progress: 246/246 securities\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/aggregate_l5.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sec_result = sec_df.groupby(['security_id', 'ts_s'], as_index=False).apply(\n",
      "[INFO] Aggregation complete: 974,894 rows\n",
      "[INFO] Merging update/cancel counts...\n",
      "[INFO] Final result: 974,894 rows\n",
      "[OK] Wrote: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_688/l2/l2_agg_1s_seg688.parquet rows= 974894\n",
      "[OK] Wrote: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_688/l2/l2_agg_1s_seg688.csv rows= 974894\n",
      "\n",
      "[Preview] First 6 rows:\n",
      "   security_id        ts_s  ...  update_count  cancel_count\n",
      "0            1  1606781709  ...            61             0\n",
      "1            1  1606781710  ...            20             0\n",
      "2            1  1606781711  ...            16             0\n",
      "3            1  1606781712  ...             1             0\n",
      "4            1  1606781714  ...             1             0\n",
      "5            1  1606781715  ...            10             0\n",
      "\n",
      "[6 rows x 22 columns]\n",
      "\u001b[92mâœ… Aggregates ready: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_688/l2/l2_agg_1s_seg688.parquet\u001b[0m\n",
      "\u001b[92mâœ… Metadata saved: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_688/metadata.json\u001b[0m\n",
      "\n",
      "\u001b[94m============================================================\u001b[0m\n",
      "\u001b[1mâœ… Segment 688 processing complete!\u001b[0m\n",
      "\u001b[94m============================================================\u001b[0m\n",
      "\n",
      "Duration: 838 seconds\n",
      "Output: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_688\n",
      "\n",
      "\n",
      "============================================================\n",
      "BATCH PROCESSING COMPLETE\n",
      "============================================================\n",
      "Total duration: 838 seconds\n",
      "Segments processed: 1\n",
      "Success: 1\n",
      "Failed: 0\n",
      "\n",
      "Detailed results:\n",
      "  âœ… Segment   688:   838s\n",
      "\n",
      "ðŸ“Š Summary saved: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/batch_summary.json\n"
     ]
    }
   ],
   "source": [
    "# OPTIMIZED MODE: Process segments, excluding large ones that cause OOM\n",
    "\n",
    "# Segment detection\n",
    "AUTO_DETECT = False  # âš ï¸ Manual segment list (excluding large ones)\n",
    "SEGMENTS = \"688\"  # Segments that fit in memory\n",
    "\n",
    "# Depth detection\n",
    "AUTO_DEPTH = True    # âœ… Use optimal depth per segment from depth summary\n",
    "MAX_LEVELS = None    # Not used when AUTO_DEPTH=True\n",
    "\n",
    "# Processing options\n",
    "PARALLEL = 2         # Process 2 segments simultaneously (recommended)\n",
    "SKIP_EXISTING = True # âš¡ Skip segments that are already completed\n",
    "\n",
    "print(\"ðŸš€ OPTIMIZED MODE - SKIP LARGE SEGMENTS\")\n",
    "print(\"=\"*70)\n",
    "print(\"Processing segments: \" + SEGMENTS)\n",
    "print(\"Skipping: 688, 1373, 1176 (too large for runtime)\")\n",
    "print(f\"Parallelism: {PARALLEL} segments at once\")\n",
    "print(f\"Skip existing: {SKIP_EXISTING} (safe to rerun)\")\n",
    "print(f\"Estimated time: 1-2 hours\")\n",
    "print(f\"Expected output: ~500 MB in Drive\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "# Build command\n",
    "cmd_parts = [\n",
    "    f'python \"{REPO_DIR}/scripts/process_all_segments.py\"',\n",
    "]\n",
    "\n",
    "if AUTO_DETECT:\n",
    "    cmd_parts.append(\"--auto-detect\")\n",
    "else:\n",
    "    cmd_parts.append(f\"--segments {SEGMENTS}\")\n",
    "\n",
    "cmd_parts.extend([\n",
    "    f'--src-local \"{RAW_LOCAL}\"',\n",
    "    f'--out-drive \"{OUT_DRIVE}\"',\n",
    "    f'--date {DATE}',\n",
    "])\n",
    "\n",
    "if AUTO_DEPTH:\n",
    "    cmd_parts.append(\"--auto-depth\")\n",
    "elif MAX_LEVELS is not None:\n",
    "    cmd_parts.append(f\"--max-levels {MAX_LEVELS}\")\n",
    "\n",
    "cmd_parts.append(f\"--parallel {PARALLEL}\")\n",
    "\n",
    "if SKIP_EXISTING:\n",
    "    cmd_parts.append(\"--skip-existing\")\n",
    "\n",
    "# Execute\n",
    "cmd = \" \\\\\\n  \".join(cmd_parts)\n",
    "print(\"Command:\")\n",
    "print(cmd)\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”§ Fix Incomplete Segments\n",
    "\n",
    "**Problem:** Some segments completed parsing (have snapshots) but failed during aggregation.\n",
    "\n",
    "**Common Issues:**\n",
    "- **Segment 1209**: NoneType error (FIXED in aggregate_l5.py)\n",
    "- **Segment 1374**: Security ID parsing error\n",
    "- **Segments 50, 1373**: OOM or interrupted\n",
    "\n",
    "**Next Steps:**\n",
    "1. Run **Cell 7** to auto-fix segments with snapshots but no aggregates\n",
    "2. Run **Cell 8** to manually retry completely failed segments (one at a time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All segments already have aggregates!\n"
     ]
    }
   ],
   "source": [
    "# Fix incomplete segments manually\n",
    "# Run this if some segments completed snapshots but not aggregation\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Check which segments need aggregation fix\n",
    "segments_to_fix = []\n",
    "\n",
    "for seg_dir in Path(OUT_DRIVE).glob(\"seg_*\"):\n",
    "    seg_id = seg_dir.name.split(\"_\")[1]\n",
    "    \n",
    "    # Check if has snapshots but no aggregates\n",
    "    has_snapshots = False\n",
    "    has_aggregates = False\n",
    "    \n",
    "    for lx_dir in seg_dir.glob(\"l*\"):\n",
    "        if list(lx_dir.glob(\"*_snapshots_*.parquet\")):\n",
    "            has_snapshots = True\n",
    "        if list(lx_dir.glob(\"*_agg_1s_*.parquet\")):\n",
    "            has_aggregates = True\n",
    "    \n",
    "    if has_snapshots and not has_aggregates:\n",
    "        segments_to_fix.append(seg_id)\n",
    "\n",
    "if segments_to_fix:\n",
    "    print(f\"ðŸ”§ Found {len(segments_to_fix)} segments needing aggregation fix:\")\n",
    "    print(f\"   Segments: {', '.join(segments_to_fix)}\")\n",
    "    print()\n",
    "    \n",
    "    for seg_id in segments_to_fix:\n",
    "        seg_dir = Path(OUT_DRIVE) / f\"seg_{seg_id}\"\n",
    "        \n",
    "        # Find the snapshot file\n",
    "        snapshot_file = None\n",
    "        di_file = None\n",
    "        mapping_file = None\n",
    "        \n",
    "        for lx_dir in seg_dir.glob(\"l*\"):\n",
    "            snapshot_files = list(lx_dir.glob(\"*_snapshots_*.parquet\"))\n",
    "            if snapshot_files:\n",
    "                snapshot_file = snapshot_files[0]\n",
    "                break\n",
    "        \n",
    "        di_files = list(seg_dir.glob(\"DI_*.csv\"))\n",
    "        if di_files:\n",
    "            di_file = di_files[0]\n",
    "        \n",
    "        mapping_files = list(seg_dir.glob(\"di_mapping.json\"))\n",
    "        if mapping_files:\n",
    "            mapping_file = mapping_files[0]\n",
    "        \n",
    "        if snapshot_file and di_file and mapping_file:\n",
    "            print(f\"â–¶ Fixing segment {seg_id}...\")\n",
    "            cmd = f'python \"{REPO_DIR}/scripts/aggregate_l5.py\" \\\\\\n'\n",
    "            cmd += f'  --seg {seg_id} \\\\\\n'\n",
    "            cmd += f'  --l5 \"{snapshot_file}\" \\\\\\n'\n",
    "            cmd += f'  --di \"{di_file}\" \\\\\\n'\n",
    "            cmd += f'  --mapping \"{mapping_file}\" \\\\\\n'\n",
    "            cmd += f'  --out \"{seg_dir}\"'\n",
    "            \n",
    "            print(cmd)\n",
    "            print()\n",
    "            os.system(cmd)\n",
    "            print()\n",
    "        else:\n",
    "            print(f\"âš ï¸  Segment {seg_id}: Missing required files\")\n",
    "            print(f\"   Snapshot: {snapshot_file}\")\n",
    "            print(f\"   DI: {di_file}\")\n",
    "            print(f\"   Mapping: {mapping_file}\")\n",
    "    \n",
    "    print(\"âœ… Aggregation fixes complete!\")\n",
    "else:\n",
    "    print(\"âœ… All segments already have aggregates!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume Segment 50 from Checkpoint\n",
    "\n",
    "The parsing and batching completed successfully, but the final merge OOM'd. Use this cell to resume from the 21 merged batch files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Resuming segment 50 merge from checkpoint\n",
      "======================================================================\n",
      "Temp dir: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_50/l5/_temp_chunks\n",
      "Output dir: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_50\n",
      "Strategy: Merge 5 batches at a time to minimize memory\n",
      "======================================================================\n",
      "\n",
      "[INFO] Found 21 merged batch files\n",
      "[INFO] Starting ultra-conservative merge (5 files at a time)...\n",
      "  Super-batch 1/5: merging 5 files...\n",
      "    Loading merged_0000.parquet...\n",
      "    Loading merged_0020.parquet...\n",
      "    Loading merged_0040.parquet...\n",
      "    Loading merged_0060.parquet...\n",
      "    Loading merged_0080.parquet...\n",
      "    Concatenating 5 dataframes...\n",
      "    Sorting 5,000,000 rows...\n",
      "    Writing to final_batch_01.parquet...\n",
      "    âœ… Super-batch 1 complete, freed memory\n",
      "  Super-batch 2/5: merging 5 files...\n",
      "    Loading merged_0100.parquet...\n",
      "    Loading merged_0120.parquet...\n",
      "    Loading merged_0140.parquet...\n",
      "    Loading merged_0160.parquet...\n",
      "    Loading merged_0180.parquet...\n",
      "    Concatenating 5 dataframes...\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/resume_merge_seg50.py:49: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  super_batch_df = pd.concat(dfs, ignore_index=True)\n",
      "    Sorting 5,000,000 rows...\n",
      "    Writing to final_batch_02.parquet...\n",
      "    âœ… Super-batch 2 complete, freed memory\n",
      "  Super-batch 3/5: merging 5 files...\n",
      "    Loading merged_0200.parquet...\n",
      "    Loading merged_0220.parquet...\n",
      "    Loading merged_0240.parquet...\n",
      "    Loading merged_0260.parquet...\n",
      "    Loading merged_0280.parquet...\n",
      "    Concatenating 5 dataframes...\n",
      "    Sorting 5,000,000 rows...\n",
      "    Writing to final_batch_03.parquet...\n",
      "    âœ… Super-batch 3 complete, freed memory\n",
      "  Super-batch 4/5: merging 5 files...\n",
      "    Loading merged_0300.parquet...\n",
      "    Loading merged_0320.parquet...\n",
      "    Loading merged_0340.parquet...\n",
      "    Loading merged_0360.parquet...\n",
      "    Loading merged_0380.parquet...\n",
      "    Concatenating 5 dataframes...\n",
      "    Sorting 5,000,000 rows...\n",
      "    Writing to final_batch_04.parquet...\n",
      "    âœ… Super-batch 4 complete, freed memory\n",
      "  Super-batch 5/5: merging 1 files...\n",
      "    Loading merged_0400.parquet...\n",
      "    Concatenating 1 dataframes...\n",
      "    Sorting 309,026 rows...\n",
      "    Writing to final_batch_05.parquet...\n",
      "    âœ… Super-batch 5 complete, freed memory\n",
      "\n",
      "[INFO] Created 5 super-batches\n",
      "[INFO] Final merge using pairwise combination to minimize memory...\n",
      "\n",
      "[Round 1] Merging 5 files pairwise...\n",
      "  Merging final_batch_01.parquet + final_batch_02.parquet...\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/resume_merge_seg50.py:92: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_merged = pd.concat([df1, df2], ignore_index=True)\n",
      "    â†’ round1_pair0.parquet (10,000,000 rows)\n",
      "  Merging final_batch_03.parquet + final_batch_04.parquet...\n",
      "    â†’ round1_pair1.parquet (10,000,000 rows)\n",
      "  Carrying forward final_batch_05.parquet\n",
      "\n",
      "[Round 2] Merging 3 files pairwise...\n",
      "  Merging round1_pair0.parquet + round1_pair1.parquet...\n",
      "    â†’ round2_pair0.parquet (20,000,000 rows)\n",
      "  Carrying forward final_batch_05.parquet\n",
      "\n",
      "[Round 3] Merging 2 files pairwise...\n",
      "  Merging round2_pair0.parquet + final_batch_05.parquet...\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Resume segment 50 merge from existing batch files\n",
    "# This uses an ultra-conservative approach: merges 5 files at a time\n",
    "\n",
    "SEG = 50\n",
    "TEMP_DIR = f\"{OUT_DRIVE}/seg_{SEG}/l5/_temp_chunks\"\n",
    "OUT_DIR = f\"{OUT_DRIVE}/seg_{SEG}\"\n",
    "\n",
    "print(f\"ðŸ”„ Resuming segment {SEG} merge from checkpoint\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Temp dir: {TEMP_DIR}\")\n",
    "print(f\"Output dir: {OUT_DIR}\")\n",
    "print(\"Strategy: Merge 5 batches at a time to minimize memory\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "!python \"{REPO_DIR}/scripts/resume_merge_seg50.py\" \\\n",
    "  --seg {SEG} \\\n",
    "  --temp-dir \"{TEMP_DIR}\" \\\n",
    "  --out-dir \"{OUT_DIR}\" \\\n",
    "  --levels 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check processing results\n",
    "\n",
    "Review the batch summary and individual segment outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5 segments in 320s\n",
      "Success: 1, Failed: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-0c20f7a6-d762-4700-bd01-d4c4f6f1a7c9\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>success</th>\n",
       "      <th>duration_sec</th>\n",
       "      <th>exit_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>688</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1209</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>228</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1374</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1373</td>\n",
       "      <td>False</td>\n",
       "      <td>302</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c20f7a6-d762-4700-bd01-d4c4f6f1a7c9')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-0c20f7a6-d762-4700-bd01-d4c4f6f1a7c9 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-0c20f7a6-d762-4700-bd01-d4c4f6f1a7c9');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   segment  success  duration_sec  exit_code\n",
       "0      688    False            11          1\n",
       "1     1209     True             7          0\n",
       "2       50    False           228          1\n",
       "3     1374    False             6          1\n",
       "4     1373    False           302          1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load batch summary\n",
    "summary_path = f\"{OUT_DRIVE}/batch_summary.json\"\n",
    "if os.path.exists(summary_path):\n",
    "    with open(summary_path) as f:\n",
    "        summary = json.load(f)\n",
    "    \n",
    "    print(f\"Processed {len(summary['results'])} segments in {summary['overall_duration_sec']}s\")\n",
    "    print(f\"Success: {summary['success_count']}, Failed: {summary['fail_count']}\")\n",
    "    \n",
    "    # Show results table\n",
    "    df = pd.DataFrame(summary['results'])\n",
    "    display(df)\n",
    "else:\n",
    "    print(\"No summary found yet. Run processing first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect a specific segment's output\n",
    "\n",
    "Check the files generated for one segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Depth subdirectories:\n",
      "\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_821/l5:\n",
      "total 59M\n",
      "-rw------- 1 root root  28M Nov 16 15:00 l5_agg_1s_seg821.csv\n",
      "-rw------- 1 root root 4.8M Nov 16 14:59 l5_agg_1s_seg821.parquet\n",
      "-rw------- 1 root root  22M Nov 16 14:57 l5_snapshots_seg821.csv\n",
      "-rw------- 1 root root 4.3M Nov 16 14:57 l5_snapshots_seg821.parquet\n"
     ]
    }
   ],
   "source": [
    "# Pick a segment to inspect\n",
    "SEG = 821\n",
    "seg_dir = f\"{OUT_DRIVE}/seg_{SEG}\"\n",
    "\n",
    "if os.path.exists(seg_dir):\n",
    "    print(f\"Output for segment {SEG}:\")\n",
    "    !ls -lh \"{seg_dir}\"\n",
    "    \n",
    "    # Show metadata\n",
    "    metadata_path = f\"{seg_dir}/metadata.json\"\n",
    "    if os.path.exists(metadata_path):\n",
    "        with open(metadata_path) as f:\n",
    "            meta = json.load(f)\n",
    "        print(\"\\nMetadata:\")\n",
    "        for k, v in meta.items():\n",
    "            print(f\"  {k}: {v}\")\n",
    "    \n",
    "    # Check L{depth} subdirectory\n",
    "    l_dirs = !ls -d \"{seg_dir}\"/l*\n",
    "    if l_dirs:\n",
    "        print(f\"\\nDepth subdirectories:\")\n",
    "        for ld in l_dirs:\n",
    "            print(f\"\\n{ld}:\")\n",
    "            !ls -lh \"{ld}\"\n",
    "else:\n",
    "    print(f\"Segment {SEG} not yet processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick preview of aggregated data\n",
    "\n",
    "Load and inspect the 1-second aggregates for a segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 153058 rows from /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_segments/seg_589/l5/l5_agg_1s_seg589.parquet\n",
      "\n",
      "Columns: ['security_id', 'ts_s', 'best_bid', 'best_ask', 'bid_size_1', 'ask_size_1', 'spread_abs', 'spread_rel', 'midprice', 'imbalance_l1', 'microprice_l1', 'total_bid_volume', 'total_ask_volume', 'avg_bid_price', 'avg_ask_price', 'imbalance_l5', 'microprice_l5', 'depth_ratio', 'total_volume', 'volume_ratio_l1_to_l5', 'update_count', 'cancel_count']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-3fd32f61-4a84-40ea-bd1e-d01b50f478a2\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>security_id</th>\n",
       "      <th>ts_s</th>\n",
       "      <th>best_bid</th>\n",
       "      <th>best_ask</th>\n",
       "      <th>bid_size_1</th>\n",
       "      <th>ask_size_1</th>\n",
       "      <th>spread_abs</th>\n",
       "      <th>spread_rel</th>\n",
       "      <th>midprice</th>\n",
       "      <th>imbalance_l1</th>\n",
       "      <th>...</th>\n",
       "      <th>total_ask_volume</th>\n",
       "      <th>avg_bid_price</th>\n",
       "      <th>avg_ask_price</th>\n",
       "      <th>imbalance_l5</th>\n",
       "      <th>microprice_l5</th>\n",
       "      <th>depth_ratio</th>\n",
       "      <th>total_volume</th>\n",
       "      <th>volume_ratio_l1_to_l5</th>\n",
       "      <th>update_count</th>\n",
       "      <th>cancel_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5035771</td>\n",
       "      <td>1606781706</td>\n",
       "      <td>13406.0</td>\n",
       "      <td>13407.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>13406.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13380.650000</td>\n",
       "      <td>13403.950000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13392.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>517</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5035771</td>\n",
       "      <td>1606781707</td>\n",
       "      <td>13404.5</td>\n",
       "      <td>13353.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>-0.003812</td>\n",
       "      <td>13379.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13397.800000</td>\n",
       "      <td>13394.444444</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>13396.033918</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5035771</td>\n",
       "      <td>1606781708</td>\n",
       "      <td>13391.5</td>\n",
       "      <td>13399.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>13395.50</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13392.961538</td>\n",
       "      <td>13398.147059</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>13396.096969</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5035771</td>\n",
       "      <td>1606781709</td>\n",
       "      <td>13337.0</td>\n",
       "      <td>13406.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.005160</td>\n",
       "      <td>13371.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13396.205882</td>\n",
       "      <td>13400.888889</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>13399.267848</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5035771</td>\n",
       "      <td>1606781710</td>\n",
       "      <td>13428.0</td>\n",
       "      <td>13436.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>13432.00</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13397.428571</td>\n",
       "      <td>13427.450000</td>\n",
       "      <td>-0.481481</td>\n",
       "      <td>13405.211905</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5035771</td>\n",
       "      <td>1606781711</td>\n",
       "      <td>13427.0</td>\n",
       "      <td>13435.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>13431.00</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13393.545455</td>\n",
       "      <td>13422.428571</td>\n",
       "      <td>-0.120000</td>\n",
       "      <td>13406.254026</td>\n",
       "      <td>1.272727</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5035771</td>\n",
       "      <td>1606781712</td>\n",
       "      <td>13414.5</td>\n",
       "      <td>13367.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-47.5</td>\n",
       "      <td>-0.003547</td>\n",
       "      <td>13390.75</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13403.181818</td>\n",
       "      <td>13393.264706</td>\n",
       "      <td>-0.214286</td>\n",
       "      <td>13399.285810</td>\n",
       "      <td>1.545455</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5035771</td>\n",
       "      <td>1606781713</td>\n",
       "      <td>13333.5</td>\n",
       "      <td>13421.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.006578</td>\n",
       "      <td>13377.50</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13388.000000</td>\n",
       "      <td>13405.812500</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>13396.312500</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5035771</td>\n",
       "      <td>1606781714</td>\n",
       "      <td>13409.0</td>\n",
       "      <td>13417.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>13413.00</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>13399.250000</td>\n",
       "      <td>13410.211538</td>\n",
       "      <td>-0.368421</td>\n",
       "      <td>13402.711538</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5035771</td>\n",
       "      <td>1606781715</td>\n",
       "      <td>13337.0</td>\n",
       "      <td>13397.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>0.004526</td>\n",
       "      <td>13367.25</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13372.666667</td>\n",
       "      <td>13393.800000</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>13382.059259</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 22 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3fd32f61-4a84-40ea-bd1e-d01b50f478a2')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-3fd32f61-4a84-40ea-bd1e-d01b50f478a2 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-3fd32f61-4a84-40ea-bd1e-d01b50f478a2');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   security_id        ts_s  best_bid  best_ask  bid_size_1  ask_size_1  \\\n",
       "0      5035771  1606781706   13406.0   13407.5         1.0         1.0   \n",
       "1      5035771  1606781707   13404.5   13353.5         1.0         1.0   \n",
       "2      5035771  1606781708   13391.5   13399.5         7.0         1.0   \n",
       "3      5035771  1606781709   13337.0   13406.0         1.0         1.0   \n",
       "4      5035771  1606781710   13428.0   13436.0         1.0         9.0   \n",
       "5      5035771  1606781711   13427.0   13435.0         1.0         7.0   \n",
       "6      5035771  1606781712   13414.5   13367.0         1.0         5.0   \n",
       "7      5035771  1606781713   13333.5   13421.5         1.0         3.0   \n",
       "8      5035771  1606781714   13409.0   13417.0         1.0         8.0   \n",
       "9      5035771  1606781715   13337.0   13397.5         1.0         4.0   \n",
       "\n",
       "   spread_abs  spread_rel  midprice  imbalance_l1  ...  total_ask_volume  \\\n",
       "0         1.5    0.000112  13406.75      0.000000  ...              10.0   \n",
       "1       -51.0   -0.003812  13379.00      0.000000  ...               9.0   \n",
       "2         8.0    0.000597  13395.50      0.750000  ...              17.0   \n",
       "3        69.0    0.005160  13371.50      0.000000  ...               9.0   \n",
       "4         8.0    0.000596  13432.00     -0.800000  ...              20.0   \n",
       "5         8.0    0.000596  13431.00     -0.750000  ...              14.0   \n",
       "6       -47.5   -0.003547  13390.75     -0.666667  ...              17.0   \n",
       "7        88.0    0.006578  13377.50     -0.500000  ...               8.0   \n",
       "8         8.0    0.000596  13413.00     -0.777778  ...              26.0   \n",
       "9        60.5    0.004526  13367.25     -0.600000  ...              15.0   \n",
       "\n",
       "   avg_bid_price  avg_ask_price  imbalance_l5  microprice_l5  depth_ratio  \\\n",
       "0   13380.650000   13403.950000      0.000000   13392.300000     1.000000   \n",
       "1   13397.800000   13394.444444      0.052632   13396.033918     0.900000   \n",
       "2   13392.961538   13398.147059      0.209302   13396.096969     0.653846   \n",
       "3   13396.205882   13400.888889      0.307692   13399.267848     0.529412   \n",
       "4   13397.428571   13427.450000     -0.481481   13405.211905     2.857143   \n",
       "5   13393.545455   13422.428571     -0.120000   13406.254026     1.272727   \n",
       "6   13403.181818   13393.264706     -0.214286   13399.285810     1.545455   \n",
       "7   13388.000000   13405.812500     -0.066667   13396.312500     1.142857   \n",
       "8   13399.250000   13410.211538     -0.368421   13402.711538     2.166667   \n",
       "9   13372.666667   13393.800000     -0.111111   13382.059259     1.250000   \n",
       "\n",
       "   total_volume  volume_ratio_l1_to_l5  update_count  cancel_count  \n",
       "0          20.0               0.100000           517             0  \n",
       "1          19.0               0.105263           231             0  \n",
       "2          43.0               0.186047           134             0  \n",
       "3          26.0               0.076923            95             0  \n",
       "4          27.0               0.370370           213             0  \n",
       "5          25.0               0.320000            41             0  \n",
       "6          28.0               0.214286            32             0  \n",
       "7          15.0               0.266667             7             0  \n",
       "8          38.0               0.236842           107             0  \n",
       "9          27.0               0.185185           172             0  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic stats:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-dc646c1a-41b9-4eb8-837b-1c3471e1bcc4\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spread_abs</th>\n",
       "      <th>spread_rel</th>\n",
       "      <th>imbalance_l1</th>\n",
       "      <th>total_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>153054.000000</td>\n",
       "      <td>152497.000000</td>\n",
       "      <td>153054.000000</td>\n",
       "      <td>153058.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.691550</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.012406</td>\n",
       "      <td>18.369938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.336317</td>\n",
       "      <td>0.079737</td>\n",
       "      <td>0.431020</td>\n",
       "      <td>13.505417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-75.000000</td>\n",
       "      <td>-7.714286</td>\n",
       "      <td>-0.967742</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.500000</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>421.000000</td>\n",
       "      <td>5.619048</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>488.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc646c1a-41b9-4eb8-837b-1c3471e1bcc4')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-dc646c1a-41b9-4eb8-837b-1c3471e1bcc4 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-dc646c1a-41b9-4eb8-837b-1c3471e1bcc4');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "          spread_abs     spread_rel   imbalance_l1   total_volume\n",
       "count  153054.000000  152497.000000  153054.000000  153058.000000\n",
       "mean        5.691550       0.001197       0.012406      18.369938\n",
       "std        13.336317       0.079737       0.431020      13.505417\n",
       "min       -75.000000      -7.714286      -0.967742       1.000000\n",
       "25%         1.500000       0.000112      -0.333333       7.000000\n",
       "50%         3.500000       0.000261       0.000000      18.000000\n",
       "75%         8.500000       0.000634       0.333333      27.000000\n",
       "max       421.000000       5.619048       0.964912     488.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEG = 589\n",
    "\n",
    "# Find the aggregates file (L{depth} may vary)\n",
    "import glob\n",
    "agg_files = glob.glob(f\"{OUT_DRIVE}/seg_{SEG}/l*/l*_agg_1s_seg{SEG}.parquet\")\n",
    "\n",
    "if agg_files:\n",
    "    df = pd.read_parquet(agg_files[0])\n",
    "    print(f\"Loaded {len(df)} rows from {agg_files[0]}\")\n",
    "    print(f\"\\nColumns: {list(df.columns)}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    display(df.head(10))\n",
    "    \n",
    "    print(f\"\\nBasic stats:\")\n",
    "    display(df[['spread_abs', 'spread_rel', 'imbalance_l1', 'total_volume']].describe())\n",
    "else:\n",
    "    print(f\"No aggregates found for segment {SEG}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Go to `3_db_setup.ipynb` and check the DuckDB setups\n",
    "2. Create Power BI dashboard with interactive filters:\n",
    "   - Segment/Product selector\n",
    "   - Granularity toggle (1s, 5s, 1m)\n",
    "   - Depth level selector (L1, L5, L10, L20)\n",
    "   - Visual type selector (spread, imbalance, volume, etc.)\n",
    "3. Export dashboard as PBIP for version control"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
