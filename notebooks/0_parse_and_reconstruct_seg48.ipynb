{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Parse and order book reconstruction (Seg=48)\n",
    "\n",
    "This notebook contains instructions and command cells only; the logic lives in `src/` and `scripts/`.\n",
    "Please make sure `0_env_data_prep.ipynb` has been run (dependencies + DuckDB init) before proceeding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPO_DIR = /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo\n",
      "SRC_ROOT = /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_raw/Sample_Eurex_20201201_10MktSegID\n",
      "DI exists under SRC_ROOT? True\n"
     ]
    }
   ],
   "source": [
    "# Repository path\n",
    "import os\n",
    "REPO_DIR = '/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo'\n",
    "assert os.path.exists(REPO_DIR), f'Repo not found: {REPO_DIR}'\n",
    "\n",
    "# Source root (use Google Drive persistent extraction)\n",
    "SRC_ROOT = f\"{REPO_DIR}/data_raw/Sample_Eurex_20201201_10MktSegID\"\n",
    "assert os.path.exists(SRC_ROOT), f\"Source root not found: {SRC_ROOT}\"\n",
    "\n",
    "print(\"REPO_DIR =\", REPO_DIR)\n",
    "print(\"SRC_ROOT =\", SRC_ROOT)\n",
    "print(\"DI exists under SRC_ROOT?\", any(fn.endswith(\"DI_48_20201201.csv\") for dp, dn, fns in os.walk(SRC_ROOT) for fn in fns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propose Seg=48 opening window (continuous trading, first 10 minutes)\n",
    "\n",
    "The script will scan DI timestamps (and optionally ISC/PSC) to detect the opening\n",
    "minute of sustained activity and propose a 10-minute window. This step does not\n",
    "perform slicing yet; it only writes a JSON manifest for your review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/make_samples.py:52: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  return dt.datetime.utcfromtimestamp(ns / 1_000_000_000).replace(second=0, microsecond=0)\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/make_samples.py:104: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  return dt.datetime.utcfromtimestamp(sec).strftime(\"%Y-%m-%dT%H:%M:%S\") + f\".{rem_ns:09d}Z\"\n",
      "== Proposed window ==\n",
      "{\n",
      "  \"segment\": 48,\n",
      "  \"open_ns\": 1606809660000000000,\n",
      "  \"open_iso\": \"2020-12-01T08:01:00.000000000Z\",\n",
      "  \"end_ns\": 1606810260000000000,\n",
      "  \"end_iso\": \"2020-12-01T08:11:00.000000000Z\"\n",
      "}\n",
      "ISC earliest: 1606804200139187733 2020-12-01T06:30:00.139187733Z\n",
      "PSC earliest: 1606804200139187733 2020-12-01T06:30:00.139187733Z\n",
      "Saved proposal: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_samples/48-FSTK-ADSG/raw/proposed_window_seg48.json\n"
     ]
    }
   ],
   "source": [
    "# Propose window (no slicing yet)\n",
    "# This will scan DI timestamps and write a JSON manifest to data_samples/ for review.\n",
    "!python \"{REPO_DIR}/scripts/make_samples.py\" \\\n",
    "  --seg 48 \\\n",
    "  --src \"{SRC_ROOT}\" \\\n",
    "  --out \"{REPO_DIR}/data_samples/48-FSTK-ADSG\" \\\n",
    "  --sustain 5 \\\n",
    "  --window-minutes 10 \\\n",
    "  --propose-only\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96f280b",
   "metadata": {},
   "source": [
    "## Slice files into a 10-minute sample\n",
    "\n",
    "Use the proposed window to slice DI/DS/ISC/PSC into [open, end) and copy IS fully into `data_samples/48-FSTK-ADSG/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7c63bb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/make_samples.py:52: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  return dt.datetime.utcfromtimestamp(ns / 1_000_000_000).replace(second=0, microsecond=0)\n",
      "/content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/scripts/make_samples.py:104: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  return dt.datetime.utcfromtimestamp(sec).strftime(\"%Y-%m-%dT%H:%M:%S\") + f\".{rem_ns:09d}Z\"\n",
      "== Proposed window ==\n",
      "{\n",
      "  \"segment\": 48,\n",
      "  \"open_ns\": 1606809660000000000,\n",
      "  \"open_iso\": \"2020-12-01T08:01:00.000000000Z\",\n",
      "  \"end_ns\": 1606810260000000000,\n",
      "  \"end_iso\": \"2020-12-01T08:11:00.000000000Z\"\n",
      "}\n",
      "ISC earliest: 1606804200139187733 2020-12-01T06:30:00.139187733Z\n",
      "PSC earliest: 1606804200139187733 2020-12-01T06:30:00.139187733Z\n",
      "Saved proposal: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_samples/48-FSTK-ADSG/raw/proposed_window_seg48.json\n",
      "[INFO] Proceeding to slice files using the proposed window [open_ns, end_ns)...\n",
      "== Slicing summary ==\n",
      "  DI: written=60 scanned=7175\n",
      "  DS: written=11 scanned=9616\n",
      "  ISC: written=0 scanned=4\n",
      "  PSC: written=0 scanned=8\n",
      "  IS: written=16 scanned=16\n"
     ]
    }
   ],
   "source": [
    "# Slice files into a 10-minute sample using the proposed window\n",
    "!python \"{REPO_DIR}/scripts/make_samples.py\" \\\n",
    "  --seg 48 \\\n",
    "  --src \"{SRC_ROOT}\" \\\n",
    "  --out \"{REPO_DIR}/data_samples/48-FSTK-ADSG\" \\\n",
    "  --sustain 5 \\\n",
    "  --window-minutes 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b98eb4",
   "metadata": {},
   "source": [
    "## Inspect DI schema and write mapping JSON\n",
    "\n",
    "This step infers a minimal field mapping for DI entries from the sliced sample and writes it to `data_samples/48-FSTK-ADSG/di_mapping_seg48.json`. It also prints a few parsed entries for visual validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d53810a",
   "metadata": {},
   "source": [
    "## Check Maximum Depth in DI Data\n",
    "\n",
    "Before running multi-level construction (L5/L10/L20), verify the maximum available depth in the raw data to avoid wasting computation on non-existent levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "779f9dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking maximum depth level in DI data...\n",
      "‚è±Ô∏è  Sampling first 1000 lines (use --sample-limit for different amount)\n",
      "\n",
      "[INFO] Analyzing DI file: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_raw/Sample_Eurex_20201201_10MktSegID/48/DI_48_20201201.csv\n",
      "[INFO] Sampling first 1000 lines\n",
      "\n",
      "============================================================\n",
      "MAXIMUM DEPTH ANALYSIS\n",
      "============================================================\n",
      "Maximum price level found: 5\n",
      "Total entries analyzed: 2698\n",
      "Lines scanned: 1000\n",
      "\n",
      "Price Level Distribution:\n",
      "  Level  0:      963 entries ( 35.7%)\n",
      "  Level  2:      959 entries ( 35.5%)\n",
      "  Level  5:      776 entries ( 28.8%)\n",
      "\n",
      "============================================================\n",
      "RECOMMENDATION:\n",
      "============================================================\n",
      "‚úÖ Maximum useful level: L5\n",
      "‚ö†Ô∏è  Using --levels > 5 will not capture additional depth\n",
      "üí° Suggested configurations:\n",
      "   ‚Ä¢ L1 : Basic best bid/ask\n",
      "   ‚Ä¢ L5 : Rich market depth (recommended)\n",
      "   ‚Ä¢ L5: Maximum available depth\n"
     ]
    }
   ],
   "source": [
    "# === Check Maximum Depth Level in DI Data ===\n",
    "# This prevents wasting time constructing L10/L20 if the data only has 5 levels\n",
    "\n",
    "SEG = 48\n",
    "DI_FULL = f\"{REPO_DIR}/data_raw/Sample_Eurex_20201201_10MktSegID/48/DI_48_20201201.csv\"\n",
    "MAPPING_JSON = f\"{REPO_DIR}/data_samples/48-FSTK-ADSG/raw/di_mapping_seg48.json\"\n",
    "\n",
    "print(f\"üîç Checking maximum depth level in DI data...\")\n",
    "print(f\"‚è±Ô∏è  Sampling first 1000 lines (use --sample-limit for different amount)\")\n",
    "print(f\"\")\n",
    "\n",
    "!python \"{REPO_DIR}/scripts/check_max_depth.py\" \\\n",
    "  --di \"{DI_FULL}\" \\\n",
    "  --mapping \"{MAPPING_JSON}\" \\\n",
    "  --sample-limit 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047b33c1",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Important: Depth Analysis Results for Segment 48\n",
    "\n",
    "**This dataset contains only 3 price levels (sparse numbering):**\n",
    "- **Level 0**: ~36% of entries (best bid/ask)\n",
    "- **Level 2**: ~36% of entries (second tier)\n",
    "- **Level 5**: ~29% of entries (third tier)\n",
    "\n",
    "**Levels 1, 3, 4, 6+ do not exist in this data.**\n",
    "\n",
    "**Recommended configuration:**\n",
    "- ‚úÖ **L1**: Use for best bid/ask analysis only\n",
    "- ‚úÖ **L5**: Use for maximum depth (captures all 3 actual levels: 0, 2, 5)\n",
    "- ‚ùå **L10/L20**: Not needed - would produce identical results to L5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c290dde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Wrote DI mapping JSON to: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_samples/48-FSTK-ADSG/raw/di_mapping_seg48.json\n",
      "{\n",
      "  \"md_update_action_idx\": 0,\n",
      "  \"entry_type_idx\": 2,\n",
      "  \"price_level_idx\": 1,\n",
      "  \"security_id_idx\": 3,\n",
      "  \"price_idx\": 5,\n",
      "  \"size_idx\": 6,\n",
      "  \"ts_ns_idx\": 9\n",
      "}\n",
      "\n",
      "[Preview] First 6 parsed entries:\n",
      "{'md_update_action': 0, 'entry_type': 0, 'price_level': 0, 'security_id': 2788279, 'price': 269.9571, 'size': 5, 'ts_ns': 1606809697524721888}\n",
      "{'md_update_action': 0, 'entry_type': 1, 'price_level': 0, 'security_id': 2788279, 'price': 270.9045, 'size': 5, 'ts_ns': 1606809697524721888}\n",
      "{'md_update_action': 0, 'entry_type': 0, 'price_level': 2, 'security_id': 2788279, 'price': 269.9571, 'size': 5, 'ts_ns': 1606809701948251798}\n",
      "{'md_update_action': 0, 'entry_type': 1, 'price_level': 2, 'security_id': 2788279, 'price': 270.9045, 'size': 5, 'ts_ns': 1606809701948251798}\n",
      "{'md_update_action': 0, 'entry_type': 0, 'price_level': 0, 'security_id': 2788279, 'price': 269.8074, 'size': 5, 'ts_ns': 1606809778487620430}\n",
      "{'md_update_action': 0, 'entry_type': 1, 'price_level': 0, 'security_id': 2788279, 'price': 270.7542, 'size': 5, 'ts_ns': 1606809778487620430}\n"
     ]
    }
   ],
   "source": [
    "# Run schema inspection on the sliced DI sample (outputs to organized structure)\n",
    "MAPPING_JSON = f\"{REPO_DIR}/data_samples/48-FSTK-ADSG/raw/di_mapping_seg48.json\"      # Updated path\n",
    "DI_SLICE = f\"{REPO_DIR}/data_samples/48-FSTK-ADSG/raw/DI_48_20201201_window.csv\"       # Updated path\n",
    "\n",
    "!python \"{REPO_DIR}/scripts/inspect_schema.py\" \\\n",
    "  --di \"{DI_SLICE}\" \\\n",
    "  --out \"{MAPPING_JSON}\" \\\n",
    "  --sample-limit 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f160bd5a",
   "metadata": {},
   "source": [
    "## Build L1 snapshots from DI\n",
    "\n",
    "This step parses the sliced DI using the inferred mapping and reconstructs best bid/ask snapshots per security. Outputs will be written to `data_samples/48-FSTK-ADSG` as Parquet and CSV for quick inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6f9312e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Wrote: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_samples/48-FSTK-ADSG/l1/l1_snapshots_seg48.parquet rows= 100\n",
      "[OK] Wrote: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_samples/48-FSTK-ADSG/l1/l1_snapshots_seg48.csv rows= 100\n",
      "\n",
      "[Preview] First 6 rows:\n",
      "                 ts_ns  best_bid  bid_size  ...  ask_size  action  security_id\n",
      "0  1606809697524721888  269.9571         5  ...       NaN       0      2788279\n",
      "1  1606809697524721888  269.9571         5  ...       5.0       0      2788279\n",
      "2  1606809778487620430  269.8074         5  ...       5.0       0      2788279\n",
      "3  1606809778487620430  269.8074         5  ...       5.0       0      2788279\n",
      "4  1606809810878532690  269.9571         5  ...       5.0       0      2788279\n",
      "5  1606809810878532690  269.9571         5  ...       5.0       0      2788279\n",
      "\n",
      "[6 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Run L1 snapshot builder (10-minute window demo)\n",
    "SEG = 48\n",
    "DI_SLICE = f\"{REPO_DIR}/data_samples/48-FSTK-ADSG/raw/DI_48_20201201_window.csv\"       # Updated path\n",
    "MAPPING_JSON = f\"{REPO_DIR}/data_samples/48-FSTK-ADSG/raw/di_mapping_seg48.json\"        # Updated path\n",
    "OUT_DIR = f\"{REPO_DIR}/data_samples/48-FSTK-ADSG\"\n",
    "\n",
    "!python \"{REPO_DIR}/scripts/parse_and_l1.py\" \\\n",
    "  --seg {SEG} \\\n",
    "  --di \"{DI_SLICE}\" \\\n",
    "  --mapping \"{MAPPING_JSON}\" \\\n",
    "  --out \"{OUT_DIR}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4c1000",
   "metadata": {},
   "source": [
    "## Aggregate to 1-second metrics\n",
    "\n",
    "This step aggregates L1 snapshots into 1-second metrics per security and joins DI action counts (updates/cancels). Outputs will be written to `data_samples/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5224f05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Wrote: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_samples/48-FSTK-ADSG/l1/l1_agg_1s_seg48.parquet rows= 33\n",
      "[OK] Wrote: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_samples/48-FSTK-ADSG/l1/l1_agg_1s_seg48.csv rows= 33\n",
      "\n",
      "[Preview] First 6 rows:\n",
      "   security_id        ts_s  best_bid  ...  microprice  update_count  cancel_count\n",
      "0      2788279  1606809697  269.9571  ...   270.43080             2             0\n",
      "1      2788279  1606809778  269.8074  ...   270.28080             2             0\n",
      "2      2788279  1606809810  269.9571  ...   270.43080             4             0\n",
      "3      2788279  1606809816  270.1068  ...   270.58075             2             0\n",
      "4      2788279  1606809824  269.9571  ...   270.43080             2             0\n",
      "5      2788279  1606809886  270.2565  ...   270.73070             2             0\n",
      "\n",
      "[6 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Run 1-second aggregation\n",
    "SEG = 48\n",
    "L1_CSV = f\"{REPO_DIR}/data_samples/48-FSTK-ADSG/l1/l1_snapshots_seg{SEG}.csv\"\n",
    "DI_SLICE = f\"{REPO_DIR}/data_samples/48-FSTK-ADSG/raw/DI_48_20201201_window.csv\"\n",
    "MAPPING_JSON = f\"{REPO_DIR}/data_samples/48-FSTK-ADSG/raw/di_mapping_seg48.json\"\n",
    "OUT_DIR = f\"{REPO_DIR}/data_samples/48-FSTK-ADSG/\"\n",
    "\n",
    "!python \"{REPO_DIR}/scripts/aggregate_1s.py\" \\\n",
    "  --seg {SEG} \\\n",
    "  --l1 \"{L1_CSV}\" \\\n",
    "  --di \"{DI_SLICE}\" \\\n",
    "  --mapping \"{MAPPING_JSON}\" \\\n",
    "  --out \"{OUT_DIR}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f9f9288e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Building L5 order book from full day data\n",
      "Input: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_raw/Sample_Eurex_20201201_10MktSegID/48/DI_48_20201201.csv\n",
      "Output: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_samples/48-FSTK-ADSG/l5/\n",
      "Note: Captures all 3 available depth levels (0, 2, 5)\n",
      "[INFO] Parsing DI file: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_raw/Sample_Eurex_20201201_10MktSegID/48/DI_48_20201201.csv\n",
      "[INFO] Tracking top 5 levels per side\n",
      "  Processed 5000 lines...\n",
      "[INFO] Processing complete:\n",
      "  Lines: 7175\n",
      "  Events: 19658\n",
      "  Changes: 19098\n",
      "  Snapshots: 19098\n",
      "[OK] Wrote: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_samples/48-FSTK-ADSG/l5/l5_snapshots_seg48.parquet rows= 19098\n",
      "[OK] Wrote: /content/drive/MyDrive/00_EUREX/eurex-liquidity-demo/data_samples/48-FSTK-ADSG/l5/l5_snapshots_seg48.csv rows= 19098\n",
      "\n",
      "[Preview] First 3 rows:\n",
      "                 ts_ns  bid_price_1  bid_size_1  ...  ask_size_5  security_id  action\n",
      "0  1606809697524721888     269.9571           5  ...        None      2788279       0\n",
      "1  1606809697524721888     269.9571           5  ...        None      2788279       0\n",
      "2  1606809701948251798     269.6577           5  ...        None      2788279       0\n",
      "\n",
      "[3 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# === Full-Day L5 Maximum Depth Order Book Construction ===\n",
    "# Build L5 snapshots using complete daily DI data\n",
    "# NOTE: This dataset only has 3 actual levels (0, 2, 5), so L5 captures ALL available depth\n",
    "\n",
    "SEG = 48\n",
    "DI_FULL = f\"{REPO_DIR}/data_raw/Sample_Eurex_20201201_10MktSegID/48/DI_48_20201201.csv\"  # Complete daily file\n",
    "MAPPING_JSON = f\"{REPO_DIR}/data_samples/48-FSTK-ADSG/raw/di_mapping_seg48.json\"          # Updated path\n",
    "OUT_DIR = f\"{REPO_DIR}/data_samples/48-FSTK-ADSG\"                                         # Base directory\n",
    "\n",
    "print(f\"üöÄ Building L5 order book from full day data\")\n",
    "print(f\"Input: {DI_FULL}\")\n",
    "print(f\"Output: {OUT_DIR}/l5/\")\n",
    "print(f\"Note: Captures all 3 available depth levels (0, 2, 5)\")\n",
    "\n",
    "!python \"{REPO_DIR}/scripts/parse_and_l5.py\" \\\n",
    "  --seg {SEG} \\\n",
    "  --di \"{DI_FULL}\" \\\n",
    "  --mapping \"{MAPPING_JSON}\" \\\n",
    "  --out \"{OUT_DIR}\" \\\n",
    "  --levels 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
